I1103 10:15:53.594034 30645 caffe.cpp:218] Using GPUs 0
I1103 10:15:53.599375 30645 caffe.cpp:223] GPU 0: GeForce GT 710
I1103 10:15:53.775552 30645 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "lenet"
solver_mode: GPU
device_id: 0
net: "lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1103 10:15:53.775645 30645 solver.cpp:87] Creating training net from net file: lenet_train_test.prototxt
I1103 10:15:53.775794 30645 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1103 10:15:53.775804 30645 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1103 10:15:53.775849 30645 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1103 10:15:53.775887 30645 layer_factory.hpp:77] Creating layer mnist
I1103 10:15:53.775957 30645 db_lmdb.cpp:35] Opened lmdb mnist_train_lmdb
I1103 10:15:53.775974 30645 net.cpp:84] Creating Layer mnist
I1103 10:15:53.775979 30645 net.cpp:380] mnist -> data
I1103 10:15:53.775993 30645 net.cpp:380] mnist -> label
I1103 10:15:53.776398 30645 data_layer.cpp:45] output data size: 64,1,28,28
I1103 10:15:53.777503 30645 net.cpp:122] Setting up mnist
I1103 10:15:53.777516 30645 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1103 10:15:53.777520 30645 net.cpp:129] Top shape: 64 (64)
I1103 10:15:53.777523 30645 net.cpp:137] Memory required for data: 200960
I1103 10:15:53.777528 30645 layer_factory.hpp:77] Creating layer conv1
I1103 10:15:53.777539 30645 net.cpp:84] Creating Layer conv1
I1103 10:15:53.777544 30645 net.cpp:406] conv1 <- data
I1103 10:15:53.777551 30645 net.cpp:380] conv1 -> conv1
I1103 10:15:54.091058 30645 net.cpp:122] Setting up conv1
I1103 10:15:54.091083 30645 net.cpp:129] Top shape: 64 20 24 24 (737280)
I1103 10:15:54.091085 30645 net.cpp:137] Memory required for data: 3150080
I1103 10:15:54.091102 30645 layer_factory.hpp:77] Creating layer pool1
I1103 10:15:54.091111 30645 net.cpp:84] Creating Layer pool1
I1103 10:15:54.091122 30645 net.cpp:406] pool1 <- conv1
I1103 10:15:54.091133 30645 net.cpp:380] pool1 -> pool1
I1103 10:15:54.091168 30645 net.cpp:122] Setting up pool1
I1103 10:15:54.091172 30645 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1103 10:15:54.091176 30645 net.cpp:137] Memory required for data: 3887360
I1103 10:15:54.091177 30645 layer_factory.hpp:77] Creating layer conv2
I1103 10:15:54.091184 30645 net.cpp:84] Creating Layer conv2
I1103 10:15:54.091187 30645 net.cpp:406] conv2 <- pool1
I1103 10:15:54.091192 30645 net.cpp:380] conv2 -> conv2
I1103 10:15:54.092274 30645 net.cpp:122] Setting up conv2
I1103 10:15:54.092283 30645 net.cpp:129] Top shape: 64 50 8 8 (204800)
I1103 10:15:54.092286 30645 net.cpp:137] Memory required for data: 4706560
I1103 10:15:54.092293 30645 layer_factory.hpp:77] Creating layer pool2
I1103 10:15:54.092298 30645 net.cpp:84] Creating Layer pool2
I1103 10:15:54.092300 30645 net.cpp:406] pool2 <- conv2
I1103 10:15:54.092303 30645 net.cpp:380] pool2 -> pool2
I1103 10:15:54.092330 30645 net.cpp:122] Setting up pool2
I1103 10:15:54.092334 30645 net.cpp:129] Top shape: 64 50 4 4 (51200)
I1103 10:15:54.092336 30645 net.cpp:137] Memory required for data: 4911360
I1103 10:15:54.092339 30645 layer_factory.hpp:77] Creating layer ip1
I1103 10:15:54.092344 30645 net.cpp:84] Creating Layer ip1
I1103 10:15:54.092347 30645 net.cpp:406] ip1 <- pool2
I1103 10:15:54.092351 30645 net.cpp:380] ip1 -> ip1
I1103 10:15:54.094310 30645 net.cpp:122] Setting up ip1
I1103 10:15:54.094319 30645 net.cpp:129] Top shape: 64 500 (32000)
I1103 10:15:54.094321 30645 net.cpp:137] Memory required for data: 5039360
I1103 10:15:54.094327 30645 layer_factory.hpp:77] Creating layer relu1
I1103 10:15:54.094331 30645 net.cpp:84] Creating Layer relu1
I1103 10:15:54.094334 30645 net.cpp:406] relu1 <- ip1
I1103 10:15:54.094338 30645 net.cpp:367] relu1 -> ip1 (in-place)
I1103 10:15:54.094624 30645 net.cpp:122] Setting up relu1
I1103 10:15:54.094631 30645 net.cpp:129] Top shape: 64 500 (32000)
I1103 10:15:54.094635 30645 net.cpp:137] Memory required for data: 5167360
I1103 10:15:54.094637 30645 layer_factory.hpp:77] Creating layer ip2
I1103 10:15:54.094641 30645 net.cpp:84] Creating Layer ip2
I1103 10:15:54.094645 30645 net.cpp:406] ip2 <- ip1
I1103 10:15:54.094648 30645 net.cpp:380] ip2 -> ip2
I1103 10:15:54.095032 30645 net.cpp:122] Setting up ip2
I1103 10:15:54.095041 30645 net.cpp:129] Top shape: 64 10 (640)
I1103 10:15:54.095043 30645 net.cpp:137] Memory required for data: 5169920
I1103 10:15:54.095048 30645 layer_factory.hpp:77] Creating layer loss
I1103 10:15:54.095053 30645 net.cpp:84] Creating Layer loss
I1103 10:15:54.095055 30645 net.cpp:406] loss <- ip2
I1103 10:15:54.095058 30645 net.cpp:406] loss <- label
I1103 10:15:54.095064 30645 net.cpp:380] loss -> loss
I1103 10:15:54.095072 30645 layer_factory.hpp:77] Creating layer loss
I1103 10:15:54.095270 30645 net.cpp:122] Setting up loss
I1103 10:15:54.095276 30645 net.cpp:129] Top shape: (1)
I1103 10:15:54.095279 30645 net.cpp:132]     with loss weight 1
I1103 10:15:54.095293 30645 net.cpp:137] Memory required for data: 5169924
I1103 10:15:54.095296 30645 net.cpp:198] loss needs backward computation.
I1103 10:15:54.095301 30645 net.cpp:198] ip2 needs backward computation.
I1103 10:15:54.095304 30645 net.cpp:198] relu1 needs backward computation.
I1103 10:15:54.095307 30645 net.cpp:198] ip1 needs backward computation.
I1103 10:15:54.095309 30645 net.cpp:198] pool2 needs backward computation.
I1103 10:15:54.095311 30645 net.cpp:198] conv2 needs backward computation.
I1103 10:15:54.095314 30645 net.cpp:198] pool1 needs backward computation.
I1103 10:15:54.095317 30645 net.cpp:198] conv1 needs backward computation.
I1103 10:15:54.095320 30645 net.cpp:200] mnist does not need backward computation.
I1103 10:15:54.095322 30645 net.cpp:242] This network produces output loss
I1103 10:15:54.095329 30645 net.cpp:255] Network initialization done.
I1103 10:15:54.095449 30645 solver.cpp:172] Creating test net (#0) specified by net file: lenet_train_test.prototxt
I1103 10:15:54.095465 30645 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1103 10:15:54.095522 30645 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1103 10:15:54.095566 30645 layer_factory.hpp:77] Creating layer mnist
I1103 10:15:54.095599 30645 db_lmdb.cpp:35] Opened lmdb mnist_test_lmdb
I1103 10:15:54.095609 30645 net.cpp:84] Creating Layer mnist
I1103 10:15:54.095613 30645 net.cpp:380] mnist -> data
I1103 10:15:54.095619 30645 net.cpp:380] mnist -> label
I1103 10:15:54.095681 30645 data_layer.cpp:45] output data size: 100,1,28,28
I1103 10:15:54.097491 30645 net.cpp:122] Setting up mnist
I1103 10:15:54.097501 30645 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1103 10:15:54.097504 30645 net.cpp:129] Top shape: 100 (100)
I1103 10:15:54.097507 30645 net.cpp:137] Memory required for data: 314000
I1103 10:15:54.097509 30645 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1103 10:15:54.097515 30645 net.cpp:84] Creating Layer label_mnist_1_split
I1103 10:15:54.097518 30645 net.cpp:406] label_mnist_1_split <- label
I1103 10:15:54.097522 30645 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1103 10:15:54.097527 30645 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1103 10:15:54.097558 30645 net.cpp:122] Setting up label_mnist_1_split
I1103 10:15:54.097563 30645 net.cpp:129] Top shape: 100 (100)
I1103 10:15:54.097565 30645 net.cpp:129] Top shape: 100 (100)
I1103 10:15:54.097568 30645 net.cpp:137] Memory required for data: 314800
I1103 10:15:54.097570 30645 layer_factory.hpp:77] Creating layer conv1
I1103 10:15:54.097576 30645 net.cpp:84] Creating Layer conv1
I1103 10:15:54.097579 30645 net.cpp:406] conv1 <- data
I1103 10:15:54.097584 30645 net.cpp:380] conv1 -> conv1
I1103 10:15:54.098824 30645 net.cpp:122] Setting up conv1
I1103 10:15:54.098835 30645 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I1103 10:15:54.098839 30645 net.cpp:137] Memory required for data: 4922800
I1103 10:15:54.098845 30645 layer_factory.hpp:77] Creating layer pool1
I1103 10:15:54.098850 30645 net.cpp:84] Creating Layer pool1
I1103 10:15:54.098858 30645 net.cpp:406] pool1 <- conv1
I1103 10:15:54.098867 30645 net.cpp:380] pool1 -> pool1
I1103 10:15:54.098896 30645 net.cpp:122] Setting up pool1
I1103 10:15:54.098901 30645 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1103 10:15:54.098903 30645 net.cpp:137] Memory required for data: 6074800
I1103 10:15:54.098906 30645 layer_factory.hpp:77] Creating layer conv2
I1103 10:15:54.098912 30645 net.cpp:84] Creating Layer conv2
I1103 10:15:54.098914 30645 net.cpp:406] conv2 <- pool1
I1103 10:15:54.098919 30645 net.cpp:380] conv2 -> conv2
I1103 10:15:54.100163 30645 net.cpp:122] Setting up conv2
I1103 10:15:54.100174 30645 net.cpp:129] Top shape: 100 50 8 8 (320000)
I1103 10:15:54.100178 30645 net.cpp:137] Memory required for data: 7354800
I1103 10:15:54.100183 30645 layer_factory.hpp:77] Creating layer pool2
I1103 10:15:54.100188 30645 net.cpp:84] Creating Layer pool2
I1103 10:15:54.100190 30645 net.cpp:406] pool2 <- conv2
I1103 10:15:54.100194 30645 net.cpp:380] pool2 -> pool2
I1103 10:15:54.100313 30645 net.cpp:122] Setting up pool2
I1103 10:15:54.100318 30645 net.cpp:129] Top shape: 100 50 4 4 (80000)
I1103 10:15:54.100320 30645 net.cpp:137] Memory required for data: 7674800
I1103 10:15:54.100324 30645 layer_factory.hpp:77] Creating layer ip1
I1103 10:15:54.100330 30645 net.cpp:84] Creating Layer ip1
I1103 10:15:54.100333 30645 net.cpp:406] ip1 <- pool2
I1103 10:15:54.100338 30645 net.cpp:380] ip1 -> ip1
I1103 10:15:54.102418 30645 net.cpp:122] Setting up ip1
I1103 10:15:54.102428 30645 net.cpp:129] Top shape: 100 500 (50000)
I1103 10:15:54.102432 30645 net.cpp:137] Memory required for data: 7874800
I1103 10:15:54.102437 30645 layer_factory.hpp:77] Creating layer relu1
I1103 10:15:54.102442 30645 net.cpp:84] Creating Layer relu1
I1103 10:15:54.102444 30645 net.cpp:406] relu1 <- ip1
I1103 10:15:54.102448 30645 net.cpp:367] relu1 -> ip1 (in-place)
I1103 10:15:54.102744 30645 net.cpp:122] Setting up relu1
I1103 10:15:54.102752 30645 net.cpp:129] Top shape: 100 500 (50000)
I1103 10:15:54.102756 30645 net.cpp:137] Memory required for data: 8074800
I1103 10:15:54.102758 30645 layer_factory.hpp:77] Creating layer ip2
I1103 10:15:54.102764 30645 net.cpp:84] Creating Layer ip2
I1103 10:15:54.102767 30645 net.cpp:406] ip2 <- ip1
I1103 10:15:54.102773 30645 net.cpp:380] ip2 -> ip2
I1103 10:15:54.102869 30645 net.cpp:122] Setting up ip2
I1103 10:15:54.102874 30645 net.cpp:129] Top shape: 100 10 (1000)
I1103 10:15:54.102875 30645 net.cpp:137] Memory required for data: 8078800
I1103 10:15:54.102880 30645 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1103 10:15:54.102883 30645 net.cpp:84] Creating Layer ip2_ip2_0_split
I1103 10:15:54.102885 30645 net.cpp:406] ip2_ip2_0_split <- ip2
I1103 10:15:54.102890 30645 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1103 10:15:54.102895 30645 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1103 10:15:54.102918 30645 net.cpp:122] Setting up ip2_ip2_0_split
I1103 10:15:54.102923 30645 net.cpp:129] Top shape: 100 10 (1000)
I1103 10:15:54.102926 30645 net.cpp:129] Top shape: 100 10 (1000)
I1103 10:15:54.102928 30645 net.cpp:137] Memory required for data: 8086800
I1103 10:15:54.102931 30645 layer_factory.hpp:77] Creating layer accuracy
I1103 10:15:54.102936 30645 net.cpp:84] Creating Layer accuracy
I1103 10:15:54.102937 30645 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I1103 10:15:54.102941 30645 net.cpp:406] accuracy <- label_mnist_1_split_0
I1103 10:15:54.102944 30645 net.cpp:380] accuracy -> accuracy
I1103 10:15:54.102951 30645 net.cpp:122] Setting up accuracy
I1103 10:15:54.102953 30645 net.cpp:129] Top shape: (1)
I1103 10:15:54.102957 30645 net.cpp:137] Memory required for data: 8086804
I1103 10:15:54.102958 30645 layer_factory.hpp:77] Creating layer loss
I1103 10:15:54.102962 30645 net.cpp:84] Creating Layer loss
I1103 10:15:54.102964 30645 net.cpp:406] loss <- ip2_ip2_0_split_1
I1103 10:15:54.102967 30645 net.cpp:406] loss <- label_mnist_1_split_1
I1103 10:15:54.102972 30645 net.cpp:380] loss -> loss
I1103 10:15:54.102975 30645 layer_factory.hpp:77] Creating layer loss
I1103 10:15:54.103185 30645 net.cpp:122] Setting up loss
I1103 10:15:54.103193 30645 net.cpp:129] Top shape: (1)
I1103 10:15:54.103194 30645 net.cpp:132]     with loss weight 1
I1103 10:15:54.103200 30645 net.cpp:137] Memory required for data: 8086808
I1103 10:15:54.103202 30645 net.cpp:198] loss needs backward computation.
I1103 10:15:54.103206 30645 net.cpp:200] accuracy does not need backward computation.
I1103 10:15:54.103209 30645 net.cpp:198] ip2_ip2_0_split needs backward computation.
I1103 10:15:54.103211 30645 net.cpp:198] ip2 needs backward computation.
I1103 10:15:54.103214 30645 net.cpp:198] relu1 needs backward computation.
I1103 10:15:54.103216 30645 net.cpp:198] ip1 needs backward computation.
I1103 10:15:54.103219 30645 net.cpp:198] pool2 needs backward computation.
I1103 10:15:54.103221 30645 net.cpp:198] conv2 needs backward computation.
I1103 10:15:54.103224 30645 net.cpp:198] pool1 needs backward computation.
I1103 10:15:54.103227 30645 net.cpp:198] conv1 needs backward computation.
I1103 10:15:54.103229 30645 net.cpp:200] label_mnist_1_split does not need backward computation.
I1103 10:15:54.103232 30645 net.cpp:200] mnist does not need backward computation.
I1103 10:15:54.103235 30645 net.cpp:242] This network produces output accuracy
I1103 10:15:54.103237 30645 net.cpp:242] This network produces output loss
I1103 10:15:54.103245 30645 net.cpp:255] Network initialization done.
I1103 10:15:54.103271 30645 solver.cpp:56] Solver scaffolding done.
I1103 10:15:54.103466 30645 caffe.cpp:248] Starting Optimization
I1103 10:15:54.103471 30645 solver.cpp:272] Solving LeNet
I1103 10:15:54.103472 30645 solver.cpp:273] Learning Rate Policy: inv
I1103 10:15:54.103849 30645 solver.cpp:330] Iteration 0, Testing net (#0)
I1103 10:15:54.967409 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:15:54.993824 30645 solver.cpp:397]     Test net output #0: accuracy = 0.0964
I1103 10:15:54.993844 30645 solver.cpp:397]     Test net output #1: loss = 2.30686 (* 1 = 2.30686 loss)
I1103 10:15:55.018710 30645 solver.cpp:218] Iteration 0 (-0.0337056 iter/s, 0.915205s/100 iters), loss = 2.31989
I1103 10:15:55.018728 30645 solver.cpp:237]     Train net output #0: loss = 2.31989 (* 1 = 2.31989 loss)
I1103 10:15:55.018738 30645 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1103 10:15:57.532892 30645 solver.cpp:218] Iteration 100 (39.7755 iter/s, 2.51411s/100 iters), loss = 0.187305
I1103 10:15:57.532922 30645 solver.cpp:237]     Train net output #0: loss = 0.187305 (* 1 = 0.187305 loss)
I1103 10:15:57.532928 30645 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I1103 10:16:00.040580 30645 solver.cpp:218] Iteration 200 (39.8787 iter/s, 2.50761s/100 iters), loss = 0.167036
I1103 10:16:00.040611 30645 solver.cpp:237]     Train net output #0: loss = 0.167036 (* 1 = 0.167036 loss)
I1103 10:16:00.040617 30645 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I1103 10:16:02.549378 30645 solver.cpp:218] Iteration 300 (39.8612 iter/s, 2.5087s/100 iters), loss = 0.189163
I1103 10:16:02.549409 30645 solver.cpp:237]     Train net output #0: loss = 0.189163 (* 1 = 0.189163 loss)
I1103 10:16:02.549414 30645 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I1103 10:16:05.053148 30645 solver.cpp:218] Iteration 400 (39.9411 iter/s, 2.50369s/100 iters), loss = 0.0894001
I1103 10:16:05.053179 30645 solver.cpp:237]     Train net output #0: loss = 0.0894 (* 1 = 0.0894 loss)
I1103 10:16:05.053186 30645 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I1103 10:16:07.518257 30645 solver.cpp:330] Iteration 500, Testing net (#0)
I1103 10:16:08.390339 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:08.416576 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9722
I1103 10:16:08.416597 30645 solver.cpp:397]     Test net output #1: loss = 0.0871809 (* 1 = 0.0871809 loss)
I1103 10:16:08.440791 30645 solver.cpp:218] Iteration 500 (29.5198 iter/s, 3.38755s/100 iters), loss = 0.141884
I1103 10:16:08.440809 30645 solver.cpp:237]     Train net output #0: loss = 0.141884 (* 1 = 0.141884 loss)
I1103 10:16:08.440820 30645 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I1103 10:16:10.943408 30645 solver.cpp:218] Iteration 600 (39.9593 iter/s, 2.50255s/100 iters), loss = 0.10082
I1103 10:16:10.943439 30645 solver.cpp:237]     Train net output #0: loss = 0.10082 (* 1 = 0.10082 loss)
I1103 10:16:10.943445 30645 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I1103 10:16:13.447186 30645 solver.cpp:218] Iteration 700 (39.9409 iter/s, 2.5037s/100 iters), loss = 0.139128
I1103 10:16:13.447216 30645 solver.cpp:237]     Train net output #0: loss = 0.139128 (* 1 = 0.139128 loss)
I1103 10:16:13.447221 30645 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I1103 10:16:15.951820 30645 solver.cpp:218] Iteration 800 (39.9273 iter/s, 2.50455s/100 iters), loss = 0.178427
I1103 10:16:15.951850 30645 solver.cpp:237]     Train net output #0: loss = 0.178427 (* 1 = 0.178427 loss)
I1103 10:16:15.951856 30645 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I1103 10:16:18.457458 30645 solver.cpp:218] Iteration 900 (39.9113 iter/s, 2.50556s/100 iters), loss = 0.180807
I1103 10:16:18.457490 30645 solver.cpp:237]     Train net output #0: loss = 0.180807 (* 1 = 0.180807 loss)
I1103 10:16:18.457496 30645 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I1103 10:16:19.285145 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:20.919896 30645 solver.cpp:330] Iteration 1000, Testing net (#0)
I1103 10:16:21.789464 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:21.817165 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9809
I1103 10:16:21.817188 30645 solver.cpp:397]     Test net output #1: loss = 0.0571041 (* 1 = 0.0571041 loss)
I1103 10:16:21.841689 30645 solver.cpp:218] Iteration 1000 (29.5496 iter/s, 3.38414s/100 iters), loss = 0.0640477
I1103 10:16:21.841709 30645 solver.cpp:237]     Train net output #0: loss = 0.0640477 (* 1 = 0.0640477 loss)
I1103 10:16:21.841717 30645 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I1103 10:16:24.356068 30645 solver.cpp:218] Iteration 1100 (39.7724 iter/s, 2.51431s/100 iters), loss = 0.00603109
I1103 10:16:24.356119 30645 solver.cpp:237]     Train net output #0: loss = 0.006031 (* 1 = 0.006031 loss)
I1103 10:16:24.356125 30645 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I1103 10:16:26.875615 30645 solver.cpp:218] Iteration 1200 (39.6913 iter/s, 2.51945s/100 iters), loss = 0.015475
I1103 10:16:26.875644 30645 solver.cpp:237]     Train net output #0: loss = 0.0154749 (* 1 = 0.0154749 loss)
I1103 10:16:26.875650 30645 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I1103 10:16:29.395002 30645 solver.cpp:218] Iteration 1300 (39.6935 iter/s, 2.51931s/100 iters), loss = 0.0139373
I1103 10:16:29.395035 30645 solver.cpp:237]     Train net output #0: loss = 0.0139372 (* 1 = 0.0139372 loss)
I1103 10:16:29.395041 30645 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I1103 10:16:31.901594 30645 solver.cpp:218] Iteration 1400 (39.8961 iter/s, 2.50651s/100 iters), loss = 0.00553036
I1103 10:16:31.901625 30645 solver.cpp:237]     Train net output #0: loss = 0.00553032 (* 1 = 0.00553032 loss)
I1103 10:16:31.901631 30645 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I1103 10:16:34.366972 30645 solver.cpp:330] Iteration 1500, Testing net (#0)
I1103 10:16:35.226055 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:35.261155 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9851
I1103 10:16:35.261215 30645 solver.cpp:397]     Test net output #1: loss = 0.0502154 (* 1 = 0.0502154 loss)
I1103 10:16:35.285322 30645 solver.cpp:218] Iteration 1500 (29.554 iter/s, 3.38364s/100 iters), loss = 0.0785995
I1103 10:16:35.285339 30645 solver.cpp:237]     Train net output #0: loss = 0.0785994 (* 1 = 0.0785994 loss)
I1103 10:16:35.285346 30645 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I1103 10:16:37.792469 30645 solver.cpp:218] Iteration 1600 (39.8871 iter/s, 2.50708s/100 iters), loss = 0.0924447
I1103 10:16:37.792500 30645 solver.cpp:237]     Train net output #0: loss = 0.0924447 (* 1 = 0.0924447 loss)
I1103 10:16:37.792512 30645 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I1103 10:16:40.326925 30645 solver.cpp:218] Iteration 1700 (39.4575 iter/s, 2.53437s/100 iters), loss = 0.017218
I1103 10:16:40.326959 30645 solver.cpp:237]     Train net output #0: loss = 0.017218 (* 1 = 0.017218 loss)
I1103 10:16:40.326967 30645 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I1103 10:16:42.898785 30645 solver.cpp:218] Iteration 1800 (38.8838 iter/s, 2.57177s/100 iters), loss = 0.0218716
I1103 10:16:42.898826 30645 solver.cpp:237]     Train net output #0: loss = 0.0218716 (* 1 = 0.0218716 loss)
I1103 10:16:42.898834 30645 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I1103 10:16:44.659170 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:45.410447 30645 solver.cpp:218] Iteration 1900 (39.8157 iter/s, 2.51157s/100 iters), loss = 0.119147
I1103 10:16:45.410480 30645 solver.cpp:237]     Train net output #0: loss = 0.119147 (* 1 = 0.119147 loss)
I1103 10:16:45.410486 30645 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I1103 10:16:47.876687 30645 solver.cpp:330] Iteration 2000, Testing net (#0)
I1103 10:16:48.741899 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:16:48.773550 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9854
I1103 10:16:48.773571 30645 solver.cpp:397]     Test net output #1: loss = 0.044277 (* 1 = 0.044277 loss)
I1103 10:16:48.797869 30645 solver.cpp:218] Iteration 2000 (29.5218 iter/s, 3.38733s/100 iters), loss = 0.0206857
I1103 10:16:48.797886 30645 solver.cpp:237]     Train net output #0: loss = 0.0206856 (* 1 = 0.0206856 loss)
I1103 10:16:48.797893 30645 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I1103 10:16:51.306720 30645 solver.cpp:218] Iteration 2100 (39.86 iter/s, 2.50878s/100 iters), loss = 0.0217319
I1103 10:16:51.306756 30645 solver.cpp:237]     Train net output #0: loss = 0.0217319 (* 1 = 0.0217319 loss)
I1103 10:16:51.306777 30645 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I1103 10:16:53.815582 30645 solver.cpp:218] Iteration 2200 (39.8601 iter/s, 2.50878s/100 iters), loss = 0.0131357
I1103 10:16:53.815623 30645 solver.cpp:237]     Train net output #0: loss = 0.0131357 (* 1 = 0.0131357 loss)
I1103 10:16:53.815629 30645 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I1103 10:16:56.319420 30645 solver.cpp:218] Iteration 2300 (39.9402 iter/s, 2.50375s/100 iters), loss = 0.092719
I1103 10:16:56.319926 30645 solver.cpp:237]     Train net output #0: loss = 0.092719 (* 1 = 0.092719 loss)
I1103 10:16:56.319936 30645 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I1103 10:16:58.824100 30645 solver.cpp:218] Iteration 2400 (39.9341 iter/s, 2.50413s/100 iters), loss = 0.011994
I1103 10:16:58.824131 30645 solver.cpp:237]     Train net output #0: loss = 0.011994 (* 1 = 0.011994 loss)
I1103 10:16:58.824138 30645 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I1103 10:17:01.289171 30645 solver.cpp:330] Iteration 2500, Testing net (#0)
I1103 10:17:02.149171 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:02.183696 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9826
I1103 10:17:02.183717 30645 solver.cpp:397]     Test net output #1: loss = 0.0547972 (* 1 = 0.0547972 loss)
I1103 10:17:02.207998 30645 solver.cpp:218] Iteration 2500 (29.5525 iter/s, 3.38381s/100 iters), loss = 0.0422744
I1103 10:17:02.208019 30645 solver.cpp:237]     Train net output #0: loss = 0.0422744 (* 1 = 0.0422744 loss)
I1103 10:17:02.208026 30645 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I1103 10:17:04.715917 30645 solver.cpp:218] Iteration 2600 (39.8748 iter/s, 2.50785s/100 iters), loss = 0.0671456
I1103 10:17:04.715948 30645 solver.cpp:237]     Train net output #0: loss = 0.0671455 (* 1 = 0.0671455 loss)
I1103 10:17:04.715955 30645 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I1103 10:17:07.233898 30645 solver.cpp:218] Iteration 2700 (39.7156 iter/s, 2.5179s/100 iters), loss = 0.0524504
I1103 10:17:07.233932 30645 solver.cpp:237]     Train net output #0: loss = 0.0524503 (* 1 = 0.0524503 loss)
I1103 10:17:07.233944 30645 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I1103 10:17:09.753283 30645 solver.cpp:218] Iteration 2800 (39.6936 iter/s, 2.5193s/100 iters), loss = 0.0042158
I1103 10:17:09.753314 30645 solver.cpp:237]     Train net output #0: loss = 0.00421577 (* 1 = 0.00421577 loss)
I1103 10:17:09.753319 30645 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I1103 10:17:09.955579 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:12.266568 30645 solver.cpp:218] Iteration 2900 (39.7899 iter/s, 2.5132s/100 iters), loss = 0.0138065
I1103 10:17:12.266600 30645 solver.cpp:237]     Train net output #0: loss = 0.0138065 (* 1 = 0.0138065 loss)
I1103 10:17:12.266607 30645 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I1103 10:17:14.735380 30645 solver.cpp:330] Iteration 3000, Testing net (#0)
I1103 10:17:15.611553 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:15.638401 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9879
I1103 10:17:15.638438 30645 solver.cpp:397]     Test net output #1: loss = 0.0401327 (* 1 = 0.0401327 loss)
I1103 10:17:15.662801 30645 solver.cpp:218] Iteration 3000 (29.4452 iter/s, 3.39614s/100 iters), loss = 0.0109039
I1103 10:17:15.662824 30645 solver.cpp:237]     Train net output #0: loss = 0.0109038 (* 1 = 0.0109038 loss)
I1103 10:17:15.662830 30645 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I1103 10:17:18.181268 30645 solver.cpp:218] Iteration 3100 (39.7078 iter/s, 2.51839s/100 iters), loss = 0.0187575
I1103 10:17:18.181300 30645 solver.cpp:237]     Train net output #0: loss = 0.0187575 (* 1 = 0.0187575 loss)
I1103 10:17:18.181306 30645 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I1103 10:17:20.696262 30645 solver.cpp:218] Iteration 3200 (39.7629 iter/s, 2.51491s/100 iters), loss = 0.0110224
I1103 10:17:20.696298 30645 solver.cpp:237]     Train net output #0: loss = 0.0110224 (* 1 = 0.0110224 loss)
I1103 10:17:20.696305 30645 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I1103 10:17:23.211200 30645 solver.cpp:218] Iteration 3300 (39.7638 iter/s, 2.51485s/100 iters), loss = 0.0131691
I1103 10:17:23.211235 30645 solver.cpp:237]     Train net output #0: loss = 0.0131691 (* 1 = 0.0131691 loss)
I1103 10:17:23.211241 30645 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I1103 10:17:25.717716 30645 solver.cpp:218] Iteration 3400 (39.8974 iter/s, 2.50643s/100 iters), loss = 0.0103397
I1103 10:17:25.717758 30645 solver.cpp:237]     Train net output #0: loss = 0.0103396 (* 1 = 0.0103396 loss)
I1103 10:17:25.717764 30645 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I1103 10:17:28.184468 30645 solver.cpp:330] Iteration 3500, Testing net (#0)
I1103 10:17:29.053956 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:29.080153 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9881
I1103 10:17:29.080174 30645 solver.cpp:397]     Test net output #1: loss = 0.0385476 (* 1 = 0.0385476 loss)
I1103 10:17:29.104518 30645 solver.cpp:218] Iteration 3500 (29.5273 iter/s, 3.3867s/100 iters), loss = 0.00422406
I1103 10:17:29.104542 30645 solver.cpp:237]     Train net output #0: loss = 0.00422404 (* 1 = 0.00422404 loss)
I1103 10:17:29.104549 30645 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I1103 10:17:31.613996 30645 solver.cpp:218] Iteration 3600 (39.8501 iter/s, 2.5094s/100 iters), loss = 0.0286618
I1103 10:17:31.614027 30645 solver.cpp:237]     Train net output #0: loss = 0.0286618 (* 1 = 0.0286618 loss)
I1103 10:17:31.614032 30645 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I1103 10:17:34.123091 30645 solver.cpp:218] Iteration 3700 (39.8563 iter/s, 2.50902s/100 iters), loss = 0.0214941
I1103 10:17:34.123121 30645 solver.cpp:237]     Train net output #0: loss = 0.0214941 (* 1 = 0.0214941 loss)
I1103 10:17:34.123127 30645 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I1103 10:17:35.251109 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:36.628434 30645 solver.cpp:218] Iteration 3800 (39.916 iter/s, 2.50526s/100 iters), loss = 0.00954455
I1103 10:17:36.628470 30645 solver.cpp:237]     Train net output #0: loss = 0.00954453 (* 1 = 0.00954453 loss)
I1103 10:17:36.628476 30645 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I1103 10:17:39.143002 30645 solver.cpp:218] Iteration 3900 (39.7697 iter/s, 2.51448s/100 iters), loss = 0.0544528
I1103 10:17:39.143039 30645 solver.cpp:237]     Train net output #0: loss = 0.0544527 (* 1 = 0.0544527 loss)
I1103 10:17:39.143046 30645 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I1103 10:17:41.612224 30645 solver.cpp:330] Iteration 4000, Testing net (#0)
I1103 10:17:42.480778 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:42.512357 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9899
I1103 10:17:42.512378 30645 solver.cpp:397]     Test net output #1: loss = 0.0316661 (* 1 = 0.0316661 loss)
I1103 10:17:42.536541 30645 solver.cpp:218] Iteration 4000 (29.4686 iter/s, 3.39344s/100 iters), loss = 0.0133675
I1103 10:17:42.536561 30645 solver.cpp:237]     Train net output #0: loss = 0.0133675 (* 1 = 0.0133675 loss)
I1103 10:17:42.536567 30645 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I1103 10:17:45.048996 30645 solver.cpp:218] Iteration 4100 (39.8028 iter/s, 2.51238s/100 iters), loss = 0.0150485
I1103 10:17:45.049028 30645 solver.cpp:237]     Train net output #0: loss = 0.0150485 (* 1 = 0.0150485 loss)
I1103 10:17:45.049033 30645 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I1103 10:17:47.561511 30645 solver.cpp:218] Iteration 4200 (39.8022 iter/s, 2.51242s/100 iters), loss = 0.0120254
I1103 10:17:47.561556 30645 solver.cpp:237]     Train net output #0: loss = 0.0120254 (* 1 = 0.0120254 loss)
I1103 10:17:47.561564 30645 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I1103 10:17:50.067319 30645 solver.cpp:218] Iteration 4300 (39.9088 iter/s, 2.50571s/100 iters), loss = 0.0472949
I1103 10:17:50.067353 30645 solver.cpp:237]     Train net output #0: loss = 0.0472949 (* 1 = 0.0472949 loss)
I1103 10:17:50.067613 30645 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I1103 10:17:52.575525 30645 solver.cpp:218] Iteration 4400 (39.8705 iter/s, 2.50812s/100 iters), loss = 0.025035
I1103 10:17:52.575561 30645 solver.cpp:237]     Train net output #0: loss = 0.025035 (* 1 = 0.025035 loss)
I1103 10:17:52.575567 30645 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I1103 10:17:55.042068 30645 solver.cpp:330] Iteration 4500, Testing net (#0)
I1103 10:17:55.913465 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:17:55.939532 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9888
I1103 10:17:55.939553 30645 solver.cpp:397]     Test net output #1: loss = 0.0363936 (* 1 = 0.0363936 loss)
I1103 10:17:55.963659 30645 solver.cpp:218] Iteration 4500 (29.5156 iter/s, 3.38804s/100 iters), loss = 0.00679205
I1103 10:17:55.963676 30645 solver.cpp:237]     Train net output #0: loss = 0.00679202 (* 1 = 0.00679202 loss)
I1103 10:17:55.963682 30645 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I1103 10:17:58.471272 30645 solver.cpp:218] Iteration 4600 (39.8797 iter/s, 2.50754s/100 iters), loss = 0.00610398
I1103 10:17:58.471444 30645 solver.cpp:237]     Train net output #0: loss = 0.00610397 (* 1 = 0.00610397 loss)
I1103 10:17:58.471452 30645 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I1103 10:18:00.558217 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:00.980374 30645 solver.cpp:218] Iteration 4700 (39.8584 iter/s, 2.50888s/100 iters), loss = 0.00349386
I1103 10:18:00.980406 30645 solver.cpp:237]     Train net output #0: loss = 0.00349387 (* 1 = 0.00349387 loss)
I1103 10:18:00.980410 30645 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I1103 10:18:03.491672 30645 solver.cpp:218] Iteration 4800 (39.8214 iter/s, 2.51122s/100 iters), loss = 0.0190596
I1103 10:18:03.491703 30645 solver.cpp:237]     Train net output #0: loss = 0.0190596 (* 1 = 0.0190596 loss)
I1103 10:18:03.491708 30645 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I1103 10:18:06.022450 30645 solver.cpp:218] Iteration 4900 (39.5149 iter/s, 2.53069s/100 iters), loss = 0.0055979
I1103 10:18:06.022486 30645 solver.cpp:237]     Train net output #0: loss = 0.0055979 (* 1 = 0.0055979 loss)
I1103 10:18:06.022495 30645 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I1103 10:18:08.524760 30645 solver.cpp:447] Snapshotting to binary proto file lenet_iter_5000.caffemodel
I1103 10:18:08.550160 30645 sgd_solver.cpp:273] Snapshotting solver state to binary proto file lenet_iter_5000.solverstate
I1103 10:18:08.551229 30645 solver.cpp:330] Iteration 5000, Testing net (#0)
I1103 10:18:09.404232 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:09.430459 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9904
I1103 10:18:09.430482 30645 solver.cpp:397]     Test net output #1: loss = 0.0303159 (* 1 = 0.0303159 loss)
I1103 10:18:09.454685 30645 solver.cpp:218] Iteration 5000 (29.1364 iter/s, 3.43214s/100 iters), loss = 0.0297887
I1103 10:18:09.454706 30645 solver.cpp:237]     Train net output #0: loss = 0.0297888 (* 1 = 0.0297888 loss)
I1103 10:18:09.454713 30645 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I1103 10:18:12.126709 30645 solver.cpp:218] Iteration 5100 (37.4259 iter/s, 2.67195s/100 iters), loss = 0.0197501
I1103 10:18:12.126741 30645 solver.cpp:237]     Train net output #0: loss = 0.0197501 (* 1 = 0.0197501 loss)
I1103 10:18:12.126746 30645 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I1103 10:18:14.687716 30645 solver.cpp:218] Iteration 5200 (39.0484 iter/s, 2.56092s/100 iters), loss = 0.00569211
I1103 10:18:14.687750 30645 solver.cpp:237]     Train net output #0: loss = 0.00569213 (* 1 = 0.00569213 loss)
I1103 10:18:14.687757 30645 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I1103 10:18:17.271095 30645 solver.cpp:218] Iteration 5300 (38.7103 iter/s, 2.58329s/100 iters), loss = 0.00214945
I1103 10:18:17.271129 30645 solver.cpp:237]     Train net output #0: loss = 0.00214947 (* 1 = 0.00214947 loss)
I1103 10:18:17.271136 30645 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I1103 10:18:19.851591 30645 solver.cpp:218] Iteration 5400 (38.7535 iter/s, 2.58041s/100 iters), loss = 0.0104333
I1103 10:18:19.851624 30645 solver.cpp:237]     Train net output #0: loss = 0.0104333 (* 1 = 0.0104333 loss)
I1103 10:18:19.851630 30645 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I1103 10:18:22.338104 30645 solver.cpp:330] Iteration 5500, Testing net (#0)
I1103 10:18:23.223948 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:23.251219 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9888
I1103 10:18:23.251245 30645 solver.cpp:397]     Test net output #1: loss = 0.0326504 (* 1 = 0.0326504 loss)
I1103 10:18:23.276700 30645 solver.cpp:218] Iteration 5500 (29.197 iter/s, 3.42501s/100 iters), loss = 0.0149814
I1103 10:18:23.276731 30645 solver.cpp:237]     Train net output #0: loss = 0.0149814 (* 1 = 0.0149814 loss)
I1103 10:18:23.276736 30645 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I1103 10:18:25.801378 30645 solver.cpp:218] Iteration 5600 (39.6103 iter/s, 2.5246s/100 iters), loss = 0.000780145
I1103 10:18:25.801411 30645 solver.cpp:237]     Train net output #0: loss = 0.000780143 (* 1 = 0.000780143 loss)
I1103 10:18:25.801431 30645 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I1103 10:18:26.316782 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:28.481814 30645 solver.cpp:218] Iteration 5700 (37.3086 iter/s, 2.68035s/100 iters), loss = 0.00271112
I1103 10:18:28.481961 30645 solver.cpp:237]     Train net output #0: loss = 0.00271113 (* 1 = 0.00271113 loss)
I1103 10:18:28.481969 30645 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I1103 10:18:31.080579 30645 solver.cpp:218] Iteration 5800 (38.4827 iter/s, 2.59857s/100 iters), loss = 0.0410834
I1103 10:18:31.080613 30645 solver.cpp:237]     Train net output #0: loss = 0.0410834 (* 1 = 0.0410834 loss)
I1103 10:18:31.080621 30645 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I1103 10:18:33.772528 30645 solver.cpp:218] Iteration 5900 (37.1492 iter/s, 2.69185s/100 iters), loss = 0.00507786
I1103 10:18:33.772574 30645 solver.cpp:237]     Train net output #0: loss = 0.00507787 (* 1 = 0.00507787 loss)
I1103 10:18:33.772583 30645 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I1103 10:18:36.329809 30645 solver.cpp:330] Iteration 6000, Testing net (#0)
I1103 10:18:37.190901 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:37.225503 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9907
I1103 10:18:37.225522 30645 solver.cpp:397]     Test net output #1: loss = 0.0286251 (* 1 = 0.0286251 loss)
I1103 10:18:37.249802 30645 solver.cpp:218] Iteration 6000 (28.759 iter/s, 3.47717s/100 iters), loss = 0.00250246
I1103 10:18:37.249822 30645 solver.cpp:237]     Train net output #0: loss = 0.00250247 (* 1 = 0.00250247 loss)
I1103 10:18:37.249830 30645 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I1103 10:18:39.774971 30645 solver.cpp:218] Iteration 6100 (39.6025 iter/s, 2.5251s/100 iters), loss = 0.00167739
I1103 10:18:39.775002 30645 solver.cpp:237]     Train net output #0: loss = 0.00167739 (* 1 = 0.00167739 loss)
I1103 10:18:39.775008 30645 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I1103 10:18:42.283419 30645 solver.cpp:218] Iteration 6200 (39.8666 iter/s, 2.50837s/100 iters), loss = 0.0130491
I1103 10:18:42.283449 30645 solver.cpp:237]     Train net output #0: loss = 0.0130491 (* 1 = 0.0130491 loss)
I1103 10:18:42.283455 30645 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I1103 10:18:44.790729 30645 solver.cpp:218] Iteration 6300 (39.8847 iter/s, 2.50723s/100 iters), loss = 0.0105615
I1103 10:18:44.790761 30645 solver.cpp:237]     Train net output #0: loss = 0.0105615 (* 1 = 0.0105615 loss)
I1103 10:18:44.790766 30645 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I1103 10:18:47.292676 30645 solver.cpp:218] Iteration 6400 (39.9702 iter/s, 2.50187s/100 iters), loss = 0.00643402
I1103 10:18:47.292709 30645 solver.cpp:237]     Train net output #0: loss = 0.00643401 (* 1 = 0.00643401 loss)
I1103 10:18:47.292716 30645 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I1103 10:18:49.753722 30645 solver.cpp:330] Iteration 6500, Testing net (#0)
I1103 10:18:50.622184 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:50.648839 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9903
I1103 10:18:50.648859 30645 solver.cpp:397]     Test net output #1: loss = 0.029425 (* 1 = 0.029425 loss)
I1103 10:18:50.673162 30645 solver.cpp:218] Iteration 6500 (29.5823 iter/s, 3.38039s/100 iters), loss = 0.0056889
I1103 10:18:50.673180 30645 solver.cpp:237]     Train net output #0: loss = 0.00568888 (* 1 = 0.00568888 loss)
I1103 10:18:50.673187 30645 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I1103 10:18:52.126667 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:18:53.177973 30645 solver.cpp:218] Iteration 6600 (39.9243 iter/s, 2.50474s/100 iters), loss = 0.0244119
I1103 10:18:53.178004 30645 solver.cpp:237]     Train net output #0: loss = 0.0244119 (* 1 = 0.0244119 loss)
I1103 10:18:53.178010 30645 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I1103 10:18:55.683787 30645 solver.cpp:218] Iteration 6700 (39.9085 iter/s, 2.50573s/100 iters), loss = 0.0102396
I1103 10:18:55.683821 30645 solver.cpp:237]     Train net output #0: loss = 0.0102396 (* 1 = 0.0102396 loss)
I1103 10:18:55.683827 30645 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I1103 10:18:58.190279 30645 solver.cpp:218] Iteration 6800 (39.8977 iter/s, 2.50641s/100 iters), loss = 0.00556179
I1103 10:18:58.190321 30645 solver.cpp:237]     Train net output #0: loss = 0.00556177 (* 1 = 0.00556177 loss)
I1103 10:18:58.190327 30645 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I1103 10:19:00.696780 30645 solver.cpp:218] Iteration 6900 (39.8977 iter/s, 2.50641s/100 iters), loss = 0.00586155
I1103 10:19:00.696988 30645 solver.cpp:237]     Train net output #0: loss = 0.00586153 (* 1 = 0.00586153 loss)
I1103 10:19:00.697000 30645 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I1103 10:19:03.179054 30645 solver.cpp:330] Iteration 7000, Testing net (#0)
I1103 10:19:04.071235 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:04.097326 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9903
I1103 10:19:04.097343 30645 solver.cpp:397]     Test net output #1: loss = 0.0291672 (* 1 = 0.0291672 loss)
I1103 10:19:04.121791 30645 solver.cpp:218] Iteration 7000 (29.1992 iter/s, 3.42475s/100 iters), loss = 0.00416274
I1103 10:19:04.121812 30645 solver.cpp:237]     Train net output #0: loss = 0.00416272 (* 1 = 0.00416272 loss)
I1103 10:19:04.121819 30645 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I1103 10:19:06.708495 30645 solver.cpp:218] Iteration 7100 (38.6605 iter/s, 2.58662s/100 iters), loss = 0.0136026
I1103 10:19:06.708547 30645 solver.cpp:237]     Train net output #0: loss = 0.0136025 (* 1 = 0.0136025 loss)
I1103 10:19:06.708559 30645 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I1103 10:19:09.244038 30645 solver.cpp:218] Iteration 7200 (39.4564 iter/s, 2.53445s/100 iters), loss = 0.00557394
I1103 10:19:09.244067 30645 solver.cpp:237]     Train net output #0: loss = 0.00557392 (* 1 = 0.00557392 loss)
I1103 10:19:09.244073 30645 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I1103 10:19:11.875946 30645 solver.cpp:218] Iteration 7300 (37.9965 iter/s, 2.63182s/100 iters), loss = 0.0184161
I1103 10:19:11.875978 30645 solver.cpp:237]     Train net output #0: loss = 0.018416 (* 1 = 0.018416 loss)
I1103 10:19:11.876000 30645 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I1103 10:19:14.486088 30645 solver.cpp:218] Iteration 7400 (38.3135 iter/s, 2.61005s/100 iters), loss = 0.00642333
I1103 10:19:14.486132 30645 solver.cpp:237]     Train net output #0: loss = 0.0064233 (* 1 = 0.0064233 loss)
I1103 10:19:14.486140 30645 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I1103 10:19:16.920240 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:17.001188 30645 solver.cpp:330] Iteration 7500, Testing net (#0)
I1103 10:19:17.882933 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:17.914744 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9903
I1103 10:19:17.914772 30645 solver.cpp:397]     Test net output #1: loss = 0.0302495 (* 1 = 0.0302495 loss)
I1103 10:19:17.943048 30645 solver.cpp:218] Iteration 7500 (28.9281 iter/s, 3.45685s/100 iters), loss = 0.000956801
I1103 10:19:17.943089 30645 solver.cpp:237]     Train net output #0: loss = 0.000956781 (* 1 = 0.000956781 loss)
I1103 10:19:17.943096 30645 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I1103 10:19:20.649574 30645 solver.cpp:218] Iteration 7600 (36.9491 iter/s, 2.70643s/100 iters), loss = 0.00654832
I1103 10:19:20.649611 30645 solver.cpp:237]     Train net output #0: loss = 0.0065483 (* 1 = 0.0065483 loss)
I1103 10:19:20.649619 30645 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I1103 10:19:23.289351 30645 solver.cpp:218] Iteration 7700 (37.8832 iter/s, 2.63969s/100 iters), loss = 0.0234194
I1103 10:19:23.289382 30645 solver.cpp:237]     Train net output #0: loss = 0.0234194 (* 1 = 0.0234194 loss)
I1103 10:19:23.289388 30645 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I1103 10:19:25.959319 30645 solver.cpp:218] Iteration 7800 (37.4549 iter/s, 2.66988s/100 iters), loss = 0.00386255
I1103 10:19:25.959363 30645 solver.cpp:237]     Train net output #0: loss = 0.00386253 (* 1 = 0.00386253 loss)
I1103 10:19:25.959370 30645 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I1103 10:19:28.520135 30645 solver.cpp:218] Iteration 7900 (39.0515 iter/s, 2.56072s/100 iters), loss = 0.00417259
I1103 10:19:28.520165 30645 solver.cpp:237]     Train net output #0: loss = 0.00417256 (* 1 = 0.00417256 loss)
I1103 10:19:28.520171 30645 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I1103 10:19:31.185613 30645 solver.cpp:330] Iteration 8000, Testing net (#0)
I1103 10:19:32.105024 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:32.136739 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9905
I1103 10:19:32.136770 30645 solver.cpp:397]     Test net output #1: loss = 0.0284603 (* 1 = 0.0284603 loss)
I1103 10:19:32.160847 30645 solver.cpp:218] Iteration 8000 (27.4679 iter/s, 3.64061s/100 iters), loss = 0.00516572
I1103 10:19:32.160872 30645 solver.cpp:237]     Train net output #0: loss = 0.00516569 (* 1 = 0.00516569 loss)
I1103 10:19:32.160879 30645 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I1103 10:19:34.720216 30645 solver.cpp:218] Iteration 8100 (39.0734 iter/s, 2.55929s/100 iters), loss = 0.0084863
I1103 10:19:34.720257 30645 solver.cpp:237]     Train net output #0: loss = 0.00848627 (* 1 = 0.00848627 loss)
I1103 10:19:34.720263 30645 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I1103 10:19:37.369386 30645 solver.cpp:218] Iteration 8200 (37.749 iter/s, 2.64908s/100 iters), loss = 0.00530921
I1103 10:19:37.369419 30645 solver.cpp:237]     Train net output #0: loss = 0.00530918 (* 1 = 0.00530918 loss)
I1103 10:19:37.369426 30645 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I1103 10:19:39.905112 30645 solver.cpp:218] Iteration 8300 (39.4378 iter/s, 2.53564s/100 iters), loss = 0.0190531
I1103 10:19:39.905144 30645 solver.cpp:237]     Train net output #0: loss = 0.019053 (* 1 = 0.019053 loss)
I1103 10:19:39.905150 30645 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I1103 10:19:42.609544 30645 solver.cpp:218] Iteration 8400 (36.9776 iter/s, 2.70434s/100 iters), loss = 0.00595414
I1103 10:19:42.609592 30645 solver.cpp:237]     Train net output #0: loss = 0.00595411 (* 1 = 0.00595411 loss)
I1103 10:19:42.609599 30645 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I1103 10:19:43.490559 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:45.153789 30645 solver.cpp:330] Iteration 8500, Testing net (#0)
I1103 10:19:46.025660 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:19:46.052206 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9906
I1103 10:19:46.052234 30645 solver.cpp:397]     Test net output #1: loss = 0.028998 (* 1 = 0.028998 loss)
I1103 10:19:46.076417 30645 solver.cpp:218] Iteration 8500 (28.8557 iter/s, 3.46552s/100 iters), loss = 0.00503469
I1103 10:19:46.076447 30645 solver.cpp:237]     Train net output #0: loss = 0.00503465 (* 1 = 0.00503465 loss)
I1103 10:19:46.076454 30645 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I1103 10:19:48.665473 30645 solver.cpp:218] Iteration 8600 (38.6255 iter/s, 2.58896s/100 iters), loss = 0.00106874
I1103 10:19:48.665519 30645 solver.cpp:237]     Train net output #0: loss = 0.00106871 (* 1 = 0.00106871 loss)
I1103 10:19:48.665526 30645 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I1103 10:19:51.420531 30645 solver.cpp:218] Iteration 8700 (36.2982 iter/s, 2.75496s/100 iters), loss = 0.00172987
I1103 10:19:51.420567 30645 solver.cpp:237]     Train net output #0: loss = 0.00172984 (* 1 = 0.00172984 loss)
I1103 10:19:51.420586 30645 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I1103 10:19:54.090345 30645 solver.cpp:218] Iteration 8800 (37.4571 iter/s, 2.66972s/100 iters), loss = 0.00139924
I1103 10:19:54.090384 30645 solver.cpp:237]     Train net output #0: loss = 0.0013992 (* 1 = 0.0013992 loss)
I1103 10:19:54.090392 30645 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I1103 10:19:56.768649 30645 solver.cpp:218] Iteration 8900 (37.3384 iter/s, 2.67821s/100 iters), loss = 0.000449568
I1103 10:19:56.768684 30645 solver.cpp:237]     Train net output #0: loss = 0.000449532 (* 1 = 0.000449532 loss)
I1103 10:19:56.768692 30645 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I1103 10:19:59.394714 30645 solver.cpp:330] Iteration 9000, Testing net (#0)
I1103 10:20:00.309465 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:20:00.341107 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9905
I1103 10:20:00.341127 30645 solver.cpp:397]     Test net output #1: loss = 0.0289109 (* 1 = 0.0289109 loss)
I1103 10:20:00.365249 30645 solver.cpp:218] Iteration 9000 (27.8048 iter/s, 3.5965s/100 iters), loss = 0.0148816
I1103 10:20:00.365288 30645 solver.cpp:237]     Train net output #0: loss = 0.0148816 (* 1 = 0.0148816 loss)
I1103 10:20:00.365294 30645 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I1103 10:20:02.870604 30645 solver.cpp:218] Iteration 9100 (39.9159 iter/s, 2.50527s/100 iters), loss = 0.00715922
I1103 10:20:02.870770 30645 solver.cpp:237]     Train net output #0: loss = 0.00715918 (* 1 = 0.00715918 loss)
I1103 10:20:02.870779 30645 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I1103 10:20:05.372783 30645 solver.cpp:218] Iteration 9200 (39.9685 iter/s, 2.50197s/100 iters), loss = 0.00164313
I1103 10:20:05.372814 30645 solver.cpp:237]     Train net output #0: loss = 0.00164309 (* 1 = 0.00164309 loss)
I1103 10:20:05.372820 30645 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I1103 10:20:07.872485 30645 solver.cpp:218] Iteration 9300 (40.0061 iter/s, 2.49962s/100 iters), loss = 0.00581743
I1103 10:20:07.872514 30645 solver.cpp:237]     Train net output #0: loss = 0.00581739 (* 1 = 0.00581739 loss)
I1103 10:20:07.872519 30645 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I1103 10:20:09.625816 30657 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:20:10.373915 30645 solver.cpp:218] Iteration 9400 (39.9784 iter/s, 2.50135s/100 iters), loss = 0.0286694
I1103 10:20:10.373946 30645 solver.cpp:237]     Train net output #0: loss = 0.0286694 (* 1 = 0.0286694 loss)
I1103 10:20:10.373952 30645 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I1103 10:20:12.830003 30645 solver.cpp:330] Iteration 9500, Testing net (#0)
I1103 10:20:13.692438 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:20:13.726981 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9894
I1103 10:20:13.727001 30645 solver.cpp:397]     Test net output #1: loss = 0.0330396 (* 1 = 0.0330396 loss)
I1103 10:20:13.751158 30645 solver.cpp:218] Iteration 9500 (29.6107 iter/s, 3.37715s/100 iters), loss = 0.00949459
I1103 10:20:13.751178 30645 solver.cpp:237]     Train net output #0: loss = 0.00949454 (* 1 = 0.00949454 loss)
I1103 10:20:13.751184 30645 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I1103 10:20:16.257756 30645 solver.cpp:218] Iteration 9600 (39.8958 iter/s, 2.50653s/100 iters), loss = 0.00300468
I1103 10:20:16.257791 30645 solver.cpp:237]     Train net output #0: loss = 0.00300463 (* 1 = 0.00300463 loss)
I1103 10:20:16.257798 30645 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I1103 10:20:18.803182 30645 solver.cpp:218] Iteration 9700 (39.2875 iter/s, 2.54534s/100 iters), loss = 0.00270949
I1103 10:20:18.803216 30645 solver.cpp:237]     Train net output #0: loss = 0.00270943 (* 1 = 0.00270943 loss)
I1103 10:20:18.803225 30645 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I1103 10:20:21.322983 30645 solver.cpp:218] Iteration 9800 (39.6872 iter/s, 2.5197s/100 iters), loss = 0.0115701
I1103 10:20:21.323014 30645 solver.cpp:237]     Train net output #0: loss = 0.0115701 (* 1 = 0.0115701 loss)
I1103 10:20:21.323020 30645 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I1103 10:20:23.835350 30645 solver.cpp:218] Iteration 9900 (39.8044 iter/s, 2.51228s/100 iters), loss = 0.00563162
I1103 10:20:23.835379 30645 solver.cpp:237]     Train net output #0: loss = 0.00563156 (* 1 = 0.00563156 loss)
I1103 10:20:23.835386 30645 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I1103 10:20:26.312635 30645 solver.cpp:447] Snapshotting to binary proto file lenet_iter_10000.caffemodel
I1103 10:20:26.334733 30645 sgd_solver.cpp:273] Snapshotting solver state to binary proto file lenet_iter_10000.solverstate
I1103 10:20:26.341841 30645 solver.cpp:310] Iteration 10000, loss = 0.00291533
I1103 10:20:26.341857 30645 solver.cpp:330] Iteration 10000, Testing net (#0)
I1103 10:20:27.193819 30658 data_layer.cpp:73] Restarting data prefetching from start.
I1103 10:20:27.225522 30645 solver.cpp:397]     Test net output #0: accuracy = 0.9908
I1103 10:20:27.225546 30645 solver.cpp:397]     Test net output #1: loss = 0.0282965 (* 1 = 0.0282965 loss)
I1103 10:20:27.225551 30645 solver.cpp:315] Optimization Done.
I1103 10:20:27.225560 30645 caffe.cpp:259] Optimization Done.

real 4m33.743s
user 3m40.720s
sys 0m58.416s
