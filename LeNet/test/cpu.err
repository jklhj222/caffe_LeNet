I1103 09:40:41.533633 28430 caffe.cpp:211] Use CPU.
I1103 09:40:41.704751 28430 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "lenet"
solver_mode: CPU
net: "lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1103 09:40:41.704829 28430 solver.cpp:87] Creating training net from net file: lenet_train_test.prototxt
I1103 09:40:41.704975 28430 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1103 09:40:41.704984 28430 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1103 09:40:41.705026 28430 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1103 09:40:41.705060 28430 layer_factory.hpp:77] Creating layer mnist
I1103 09:40:41.705129 28430 db_lmdb.cpp:35] Opened lmdb mnist_train_lmdb
I1103 09:40:41.705144 28430 net.cpp:84] Creating Layer mnist
I1103 09:40:41.705152 28430 net.cpp:380] mnist -> data
I1103 09:40:41.705166 28430 net.cpp:380] mnist -> label
I1103 09:40:41.705188 28430 data_layer.cpp:45] output data size: 64,1,28,28
I1103 09:40:41.705878 28430 net.cpp:122] Setting up mnist
I1103 09:40:41.705888 28430 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1103 09:40:41.705890 28430 net.cpp:129] Top shape: 64 (64)
I1103 09:40:41.705893 28430 net.cpp:137] Memory required for data: 200960
I1103 09:40:41.705896 28430 layer_factory.hpp:77] Creating layer conv1
I1103 09:40:41.705916 28430 net.cpp:84] Creating Layer conv1
I1103 09:40:41.705921 28430 net.cpp:406] conv1 <- data
I1103 09:40:41.705929 28430 net.cpp:380] conv1 -> conv1
I1103 09:40:42.008930 28430 net.cpp:122] Setting up conv1
I1103 09:40:42.008954 28430 net.cpp:129] Top shape: 64 20 24 24 (737280)
I1103 09:40:42.008957 28430 net.cpp:137] Memory required for data: 3150080
I1103 09:40:42.008973 28430 layer_factory.hpp:77] Creating layer pool1
I1103 09:40:42.008981 28430 net.cpp:84] Creating Layer pool1
I1103 09:40:42.008985 28430 net.cpp:406] pool1 <- conv1
I1103 09:40:42.008990 28430 net.cpp:380] pool1 -> pool1
I1103 09:40:42.009008 28430 net.cpp:122] Setting up pool1
I1103 09:40:42.009017 28430 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1103 09:40:42.009021 28430 net.cpp:137] Memory required for data: 3887360
I1103 09:40:42.009022 28430 layer_factory.hpp:77] Creating layer conv2
I1103 09:40:42.009029 28430 net.cpp:84] Creating Layer conv2
I1103 09:40:42.009032 28430 net.cpp:406] conv2 <- pool1
I1103 09:40:42.009037 28430 net.cpp:380] conv2 -> conv2
I1103 09:40:42.009948 28430 net.cpp:122] Setting up conv2
I1103 09:40:42.009956 28430 net.cpp:129] Top shape: 64 50 8 8 (204800)
I1103 09:40:42.009959 28430 net.cpp:137] Memory required for data: 4706560
I1103 09:40:42.009965 28430 layer_factory.hpp:77] Creating layer pool2
I1103 09:40:42.009970 28430 net.cpp:84] Creating Layer pool2
I1103 09:40:42.009974 28430 net.cpp:406] pool2 <- conv2
I1103 09:40:42.009976 28430 net.cpp:380] pool2 -> pool2
I1103 09:40:42.009982 28430 net.cpp:122] Setting up pool2
I1103 09:40:42.009986 28430 net.cpp:129] Top shape: 64 50 4 4 (51200)
I1103 09:40:42.009989 28430 net.cpp:137] Memory required for data: 4911360
I1103 09:40:42.009991 28430 layer_factory.hpp:77] Creating layer ip1
I1103 09:40:42.009996 28430 net.cpp:84] Creating Layer ip1
I1103 09:40:42.009999 28430 net.cpp:406] ip1 <- pool2
I1103 09:40:42.010002 28430 net.cpp:380] ip1 -> ip1
I1103 09:40:42.011829 28430 net.cpp:122] Setting up ip1
I1103 09:40:42.011835 28430 net.cpp:129] Top shape: 64 500 (32000)
I1103 09:40:42.011837 28430 net.cpp:137] Memory required for data: 5039360
I1103 09:40:42.011843 28430 layer_factory.hpp:77] Creating layer relu1
I1103 09:40:42.011847 28430 net.cpp:84] Creating Layer relu1
I1103 09:40:42.011849 28430 net.cpp:406] relu1 <- ip1
I1103 09:40:42.011853 28430 net.cpp:367] relu1 -> ip1 (in-place)
I1103 09:40:42.012132 28430 net.cpp:122] Setting up relu1
I1103 09:40:42.012140 28430 net.cpp:129] Top shape: 64 500 (32000)
I1103 09:40:42.012142 28430 net.cpp:137] Memory required for data: 5167360
I1103 09:40:42.012145 28430 layer_factory.hpp:77] Creating layer ip2
I1103 09:40:42.012151 28430 net.cpp:84] Creating Layer ip2
I1103 09:40:42.012152 28430 net.cpp:406] ip2 <- ip1
I1103 09:40:42.012156 28430 net.cpp:380] ip2 -> ip2
I1103 09:40:42.012186 28430 net.cpp:122] Setting up ip2
I1103 09:40:42.012188 28430 net.cpp:129] Top shape: 64 10 (640)
I1103 09:40:42.012190 28430 net.cpp:137] Memory required for data: 5169920
I1103 09:40:42.012194 28430 layer_factory.hpp:77] Creating layer loss
I1103 09:40:42.012199 28430 net.cpp:84] Creating Layer loss
I1103 09:40:42.012202 28430 net.cpp:406] loss <- ip2
I1103 09:40:42.012204 28430 net.cpp:406] loss <- label
I1103 09:40:42.012208 28430 net.cpp:380] loss -> loss
I1103 09:40:42.012217 28430 layer_factory.hpp:77] Creating layer loss
I1103 09:40:42.012361 28430 net.cpp:122] Setting up loss
I1103 09:40:42.012367 28430 net.cpp:129] Top shape: (1)
I1103 09:40:42.012369 28430 net.cpp:132]     with loss weight 1
I1103 09:40:42.012382 28430 net.cpp:137] Memory required for data: 5169924
I1103 09:40:42.012384 28430 net.cpp:198] loss needs backward computation.
I1103 09:40:42.012389 28430 net.cpp:198] ip2 needs backward computation.
I1103 09:40:42.012392 28430 net.cpp:198] relu1 needs backward computation.
I1103 09:40:42.012394 28430 net.cpp:198] ip1 needs backward computation.
I1103 09:40:42.012398 28430 net.cpp:198] pool2 needs backward computation.
I1103 09:40:42.012399 28430 net.cpp:198] conv2 needs backward computation.
I1103 09:40:42.012401 28430 net.cpp:198] pool1 needs backward computation.
I1103 09:40:42.012404 28430 net.cpp:198] conv1 needs backward computation.
I1103 09:40:42.012408 28430 net.cpp:200] mnist does not need backward computation.
I1103 09:40:42.012409 28430 net.cpp:242] This network produces output loss
I1103 09:40:42.012416 28430 net.cpp:255] Network initialization done.
I1103 09:40:42.012540 28430 solver.cpp:172] Creating test net (#0) specified by net file: lenet_train_test.prototxt
I1103 09:40:42.012555 28430 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1103 09:40:42.012610 28430 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1103 09:40:42.012658 28430 layer_factory.hpp:77] Creating layer mnist
I1103 09:40:42.012694 28430 db_lmdb.cpp:35] Opened lmdb mnist_test_lmdb
I1103 09:40:42.012704 28430 net.cpp:84] Creating Layer mnist
I1103 09:40:42.012708 28430 net.cpp:380] mnist -> data
I1103 09:40:42.012713 28430 net.cpp:380] mnist -> label
I1103 09:40:42.012725 28430 data_layer.cpp:45] output data size: 100,1,28,28
I1103 09:40:42.013031 28430 net.cpp:122] Setting up mnist
I1103 09:40:42.013037 28430 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1103 09:40:42.013041 28430 net.cpp:129] Top shape: 100 (100)
I1103 09:40:42.013043 28430 net.cpp:137] Memory required for data: 314000
I1103 09:40:42.013046 28430 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1103 09:40:42.013051 28430 net.cpp:84] Creating Layer label_mnist_1_split
I1103 09:40:42.013052 28430 net.cpp:406] label_mnist_1_split <- label
I1103 09:40:42.013057 28430 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1103 09:40:42.013062 28430 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1103 09:40:42.013067 28430 net.cpp:122] Setting up label_mnist_1_split
I1103 09:40:42.013070 28430 net.cpp:129] Top shape: 100 (100)
I1103 09:40:42.013073 28430 net.cpp:129] Top shape: 100 (100)
I1103 09:40:42.013075 28430 net.cpp:137] Memory required for data: 314800
I1103 09:40:42.013077 28430 layer_factory.hpp:77] Creating layer conv1
I1103 09:40:42.013084 28430 net.cpp:84] Creating Layer conv1
I1103 09:40:42.013087 28430 net.cpp:406] conv1 <- data
I1103 09:40:42.013092 28430 net.cpp:380] conv1 -> conv1
I1103 09:40:42.013962 28430 net.cpp:122] Setting up conv1
I1103 09:40:42.013972 28430 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I1103 09:40:42.013975 28430 net.cpp:137] Memory required for data: 4922800
I1103 09:40:42.013981 28430 layer_factory.hpp:77] Creating layer pool1
I1103 09:40:42.013986 28430 net.cpp:84] Creating Layer pool1
I1103 09:40:42.013989 28430 net.cpp:406] pool1 <- conv1
I1103 09:40:42.013996 28430 net.cpp:380] pool1 -> pool1
I1103 09:40:42.014006 28430 net.cpp:122] Setting up pool1
I1103 09:40:42.014012 28430 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1103 09:40:42.014014 28430 net.cpp:137] Memory required for data: 6074800
I1103 09:40:42.014017 28430 layer_factory.hpp:77] Creating layer conv2
I1103 09:40:42.014025 28430 net.cpp:84] Creating Layer conv2
I1103 09:40:42.014029 28430 net.cpp:406] conv2 <- pool1
I1103 09:40:42.014034 28430 net.cpp:380] conv2 -> conv2
I1103 09:40:42.015041 28430 net.cpp:122] Setting up conv2
I1103 09:40:42.015051 28430 net.cpp:129] Top shape: 100 50 8 8 (320000)
I1103 09:40:42.015054 28430 net.cpp:137] Memory required for data: 7354800
I1103 09:40:42.015060 28430 layer_factory.hpp:77] Creating layer pool2
I1103 09:40:42.015065 28430 net.cpp:84] Creating Layer pool2
I1103 09:40:42.015067 28430 net.cpp:406] pool2 <- conv2
I1103 09:40:42.015072 28430 net.cpp:380] pool2 -> pool2
I1103 09:40:42.015080 28430 net.cpp:122] Setting up pool2
I1103 09:40:42.015084 28430 net.cpp:129] Top shape: 100 50 4 4 (80000)
I1103 09:40:42.015087 28430 net.cpp:137] Memory required for data: 7674800
I1103 09:40:42.015089 28430 layer_factory.hpp:77] Creating layer ip1
I1103 09:40:42.015095 28430 net.cpp:84] Creating Layer ip1
I1103 09:40:42.015099 28430 net.cpp:406] ip1 <- pool2
I1103 09:40:42.015102 28430 net.cpp:380] ip1 -> ip1
I1103 09:40:42.016921 28430 net.cpp:122] Setting up ip1
I1103 09:40:42.016927 28430 net.cpp:129] Top shape: 100 500 (50000)
I1103 09:40:42.016929 28430 net.cpp:137] Memory required for data: 7874800
I1103 09:40:42.016934 28430 layer_factory.hpp:77] Creating layer relu1
I1103 09:40:42.016940 28430 net.cpp:84] Creating Layer relu1
I1103 09:40:42.016942 28430 net.cpp:406] relu1 <- ip1
I1103 09:40:42.016947 28430 net.cpp:367] relu1 -> ip1 (in-place)
I1103 09:40:42.017231 28430 net.cpp:122] Setting up relu1
I1103 09:40:42.017238 28430 net.cpp:129] Top shape: 100 500 (50000)
I1103 09:40:42.017241 28430 net.cpp:137] Memory required for data: 8074800
I1103 09:40:42.017244 28430 layer_factory.hpp:77] Creating layer ip2
I1103 09:40:42.017251 28430 net.cpp:84] Creating Layer ip2
I1103 09:40:42.017252 28430 net.cpp:406] ip2 <- ip1
I1103 09:40:42.017257 28430 net.cpp:380] ip2 -> ip2
I1103 09:40:42.017292 28430 net.cpp:122] Setting up ip2
I1103 09:40:42.017295 28430 net.cpp:129] Top shape: 100 10 (1000)
I1103 09:40:42.017297 28430 net.cpp:137] Memory required for data: 8078800
I1103 09:40:42.017302 28430 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1103 09:40:42.017305 28430 net.cpp:84] Creating Layer ip2_ip2_0_split
I1103 09:40:42.017309 28430 net.cpp:406] ip2_ip2_0_split <- ip2
I1103 09:40:42.017313 28430 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1103 09:40:42.017316 28430 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1103 09:40:42.017321 28430 net.cpp:122] Setting up ip2_ip2_0_split
I1103 09:40:42.017324 28430 net.cpp:129] Top shape: 100 10 (1000)
I1103 09:40:42.017328 28430 net.cpp:129] Top shape: 100 10 (1000)
I1103 09:40:42.017329 28430 net.cpp:137] Memory required for data: 8086800
I1103 09:40:42.017333 28430 layer_factory.hpp:77] Creating layer accuracy
I1103 09:40:42.017336 28430 net.cpp:84] Creating Layer accuracy
I1103 09:40:42.017339 28430 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I1103 09:40:42.017343 28430 net.cpp:406] accuracy <- label_mnist_1_split_0
I1103 09:40:42.017345 28430 net.cpp:380] accuracy -> accuracy
I1103 09:40:42.017350 28430 net.cpp:122] Setting up accuracy
I1103 09:40:42.017354 28430 net.cpp:129] Top shape: (1)
I1103 09:40:42.017355 28430 net.cpp:137] Memory required for data: 8086804
I1103 09:40:42.017357 28430 layer_factory.hpp:77] Creating layer loss
I1103 09:40:42.017361 28430 net.cpp:84] Creating Layer loss
I1103 09:40:42.017364 28430 net.cpp:406] loss <- ip2_ip2_0_split_1
I1103 09:40:42.017366 28430 net.cpp:406] loss <- label_mnist_1_split_1
I1103 09:40:42.017370 28430 net.cpp:380] loss -> loss
I1103 09:40:42.017375 28430 layer_factory.hpp:77] Creating layer loss
I1103 09:40:42.017518 28430 net.cpp:122] Setting up loss
I1103 09:40:42.017526 28430 net.cpp:129] Top shape: (1)
I1103 09:40:42.017534 28430 net.cpp:132]     with loss weight 1
I1103 09:40:42.017539 28430 net.cpp:137] Memory required for data: 8086808
I1103 09:40:42.017540 28430 net.cpp:198] loss needs backward computation.
I1103 09:40:42.017544 28430 net.cpp:200] accuracy does not need backward computation.
I1103 09:40:42.017547 28430 net.cpp:198] ip2_ip2_0_split needs backward computation.
I1103 09:40:42.017549 28430 net.cpp:198] ip2 needs backward computation.
I1103 09:40:42.017552 28430 net.cpp:198] relu1 needs backward computation.
I1103 09:40:42.017554 28430 net.cpp:198] ip1 needs backward computation.
I1103 09:40:42.017557 28430 net.cpp:198] pool2 needs backward computation.
I1103 09:40:42.017560 28430 net.cpp:198] conv2 needs backward computation.
I1103 09:40:42.017562 28430 net.cpp:198] pool1 needs backward computation.
I1103 09:40:42.017565 28430 net.cpp:198] conv1 needs backward computation.
I1103 09:40:42.017567 28430 net.cpp:200] label_mnist_1_split does not need backward computation.
I1103 09:40:42.017570 28430 net.cpp:200] mnist does not need backward computation.
I1103 09:40:42.017572 28430 net.cpp:242] This network produces output accuracy
I1103 09:40:42.017575 28430 net.cpp:242] This network produces output loss
I1103 09:40:42.017585 28430 net.cpp:255] Network initialization done.
I1103 09:40:42.017608 28430 solver.cpp:56] Solver scaffolding done.
I1103 09:40:42.017626 28430 caffe.cpp:248] Starting Optimization
I1103 09:40:42.017628 28430 solver.cpp:272] Solving LeNet
I1103 09:40:42.017630 28430 solver.cpp:273] Learning Rate Policy: inv
I1103 09:40:42.018038 28430 solver.cpp:330] Iteration 0, Testing net (#0)
I1103 09:40:44.514613 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:40:44.622458 28430 solver.cpp:397]     Test net output #0: accuracy = 0.1155
I1103 09:40:44.622489 28430 solver.cpp:397]     Test net output #1: loss = 2.37286 (* 1 = 2.37286 loss)
I1103 09:40:44.661031 28430 solver.cpp:218] Iteration 0 (0 iter/s, 2.643s/100 iters), loss = 2.36203
I1103 09:40:44.661065 28430 solver.cpp:237]     Train net output #0: loss = 2.36203 (* 1 = 2.36203 loss)
I1103 09:40:44.661080 28430 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1103 09:40:48.089185 28430 solver.cpp:218] Iteration 100 (29.1715 iter/s, 3.428s/100 iters), loss = 0.260325
I1103 09:40:48.089228 28430 solver.cpp:237]     Train net output #0: loss = 0.260325 (* 1 = 0.260325 loss)
I1103 09:40:48.089236 28430 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I1103 09:40:51.500211 28430 solver.cpp:218] Iteration 200 (29.3255 iter/s, 3.41s/100 iters), loss = 0.137813
I1103 09:40:51.500252 28430 solver.cpp:237]     Train net output #0: loss = 0.137813 (* 1 = 0.137813 loss)
I1103 09:40:51.500260 28430 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I1103 09:40:54.913919 28430 solver.cpp:218] Iteration 300 (29.2997 iter/s, 3.413s/100 iters), loss = 0.159069
I1103 09:40:54.913956 28430 solver.cpp:237]     Train net output #0: loss = 0.159069 (* 1 = 0.159069 loss)
I1103 09:40:54.913965 28430 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I1103 09:40:58.323225 28430 solver.cpp:218] Iteration 400 (29.3341 iter/s, 3.409s/100 iters), loss = 0.106772
I1103 09:40:58.323266 28430 solver.cpp:237]     Train net output #0: loss = 0.106772 (* 1 = 0.106772 loss)
I1103 09:40:58.323274 28430 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I1103 09:41:01.683181 28430 solver.cpp:330] Iteration 500, Testing net (#0)
I1103 09:41:04.150517 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:41:04.252215 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9736
I1103 09:41:04.252250 28430 solver.cpp:397]     Test net output #1: loss = 0.0813033 (* 1 = 0.0813033 loss)
I1103 09:41:04.285210 28430 solver.cpp:218] Iteration 500 (16.7757 iter/s, 5.961s/100 iters), loss = 0.117842
I1103 09:41:04.285245 28430 solver.cpp:237]     Train net output #0: loss = 0.117842 (* 1 = 0.117842 loss)
I1103 09:41:04.285254 28430 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I1103 09:41:07.789031 28430 solver.cpp:218] Iteration 600 (28.547 iter/s, 3.503s/100 iters), loss = 0.131757
I1103 09:41:07.789085 28430 solver.cpp:237]     Train net output #0: loss = 0.131757 (* 1 = 0.131757 loss)
I1103 09:41:07.789093 28430 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I1103 09:41:11.624694 28430 solver.cpp:218] Iteration 700 (26.0756 iter/s, 3.835s/100 iters), loss = 0.138145
I1103 09:41:11.624857 28430 solver.cpp:237]     Train net output #0: loss = 0.138145 (* 1 = 0.138145 loss)
I1103 09:41:11.624866 28430 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I1103 09:41:16.101900 28430 solver.cpp:218] Iteration 800 (22.3364 iter/s, 4.477s/100 iters), loss = 0.176583
I1103 09:41:16.101943 28430 solver.cpp:237]     Train net output #0: loss = 0.176583 (* 1 = 0.176583 loss)
I1103 09:41:16.101951 28430 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I1103 09:41:19.631989 28430 solver.cpp:218] Iteration 900 (28.3286 iter/s, 3.53s/100 iters), loss = 0.132484
I1103 09:41:19.632033 28430 solver.cpp:237]     Train net output #0: loss = 0.132484 (* 1 = 0.132484 loss)
I1103 09:41:19.632042 28430 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I1103 09:41:20.944993 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:41:23.531667 28430 solver.cpp:330] Iteration 1000, Testing net (#0)
I1103 09:41:26.934453 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:41:27.043833 28430 solver.cpp:397]     Test net output #0: accuracy = 0.981
I1103 09:41:27.043866 28430 solver.cpp:397]     Test net output #1: loss = 0.0575479 (* 1 = 0.0575479 loss)
I1103 09:41:27.078173 28430 solver.cpp:218] Iteration 1000 (13.43 iter/s, 7.446s/100 iters), loss = 0.0911121
I1103 09:41:27.078209 28430 solver.cpp:237]     Train net output #0: loss = 0.091112 (* 1 = 0.091112 loss)
I1103 09:41:27.078218 28430 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I1103 09:41:30.526378 28430 solver.cpp:218] Iteration 1100 (29.0023 iter/s, 3.448s/100 iters), loss = 0.00667024
I1103 09:41:30.526419 28430 solver.cpp:237]     Train net output #0: loss = 0.00667018 (* 1 = 0.00667018 loss)
I1103 09:41:30.526427 28430 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I1103 09:41:34.080868 28430 solver.cpp:218] Iteration 1200 (28.1373 iter/s, 3.554s/100 iters), loss = 0.0148173
I1103 09:41:34.080911 28430 solver.cpp:237]     Train net output #0: loss = 0.0148172 (* 1 = 0.0148172 loss)
I1103 09:41:34.080920 28430 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I1103 09:41:37.805716 28430 solver.cpp:218] Iteration 1300 (26.8528 iter/s, 3.724s/100 iters), loss = 0.0150107
I1103 09:41:37.805761 28430 solver.cpp:237]     Train net output #0: loss = 0.0150107 (* 1 = 0.0150107 loss)
I1103 09:41:37.805770 28430 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I1103 09:41:41.421854 28430 solver.cpp:218] Iteration 1400 (27.6549 iter/s, 3.616s/100 iters), loss = 0.00601036
I1103 09:41:41.422164 28430 solver.cpp:237]     Train net output #0: loss = 0.00601029 (* 1 = 0.00601029 loss)
I1103 09:41:41.422175 28430 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I1103 09:41:44.844792 28430 solver.cpp:330] Iteration 1500, Testing net (#0)
I1103 09:41:47.369011 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:41:47.478644 28430 solver.cpp:397]     Test net output #0: accuracy = 0.985
I1103 09:41:47.478678 28430 solver.cpp:397]     Test net output #1: loss = 0.047317 (* 1 = 0.047317 loss)
I1103 09:41:47.511636 28430 solver.cpp:218] Iteration 1500 (16.4231 iter/s, 6.089s/100 iters), loss = 0.0895211
I1103 09:41:47.511672 28430 solver.cpp:237]     Train net output #0: loss = 0.0895211 (* 1 = 0.0895211 loss)
I1103 09:41:47.511680 28430 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I1103 09:41:51.087673 28430 solver.cpp:218] Iteration 1600 (27.972 iter/s, 3.575s/100 iters), loss = 0.0826533
I1103 09:41:51.087715 28430 solver.cpp:237]     Train net output #0: loss = 0.0826531 (* 1 = 0.0826531 loss)
I1103 09:41:51.087725 28430 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I1103 09:41:54.538298 28430 solver.cpp:218] Iteration 1700 (28.9855 iter/s, 3.45s/100 iters), loss = 0.0158145
I1103 09:41:54.538338 28430 solver.cpp:237]     Train net output #0: loss = 0.0158143 (* 1 = 0.0158143 loss)
I1103 09:41:54.538347 28430 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I1103 09:41:58.105049 28430 solver.cpp:218] Iteration 1800 (28.0426 iter/s, 3.566s/100 iters), loss = 0.00987278
I1103 09:41:58.105092 28430 solver.cpp:237]     Train net output #0: loss = 0.00987259 (* 1 = 0.00987259 loss)
I1103 09:41:58.105100 28430 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I1103 09:42:00.508896 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:42:01.563554 28430 solver.cpp:218] Iteration 1900 (28.9185 iter/s, 3.458s/100 iters), loss = 0.10477
I1103 09:42:01.563598 28430 solver.cpp:237]     Train net output #0: loss = 0.10477 (* 1 = 0.10477 loss)
I1103 09:42:01.563607 28430 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I1103 09:42:04.943372 28430 solver.cpp:330] Iteration 2000, Testing net (#0)
I1103 09:42:07.437172 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:42:07.541911 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9851
I1103 09:42:07.542605 28430 solver.cpp:397]     Test net output #1: loss = 0.0422239 (* 1 = 0.0422239 loss)
I1103 09:42:07.584384 28430 solver.cpp:218] Iteration 2000 (16.6113 iter/s, 6.02s/100 iters), loss = 0.0114206
I1103 09:42:07.585126 28430 solver.cpp:237]     Train net output #0: loss = 0.0114204 (* 1 = 0.0114204 loss)
I1103 09:42:07.585765 28430 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I1103 09:42:10.997767 28430 solver.cpp:218] Iteration 2100 (29.3083 iter/s, 3.412s/100 iters), loss = 0.0159834
I1103 09:42:10.998488 28430 solver.cpp:237]     Train net output #0: loss = 0.0159832 (* 1 = 0.0159832 loss)
I1103 09:42:10.998514 28430 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I1103 09:42:14.410956 28430 solver.cpp:218] Iteration 2200 (29.3083 iter/s, 3.412s/100 iters), loss = 0.0191488
I1103 09:42:14.411999 28430 solver.cpp:237]     Train net output #0: loss = 0.0191486 (* 1 = 0.0191486 loss)
I1103 09:42:14.412657 28430 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I1103 09:42:17.839637 28430 solver.cpp:218] Iteration 2300 (29.18 iter/s, 3.427s/100 iters), loss = 0.0680951
I1103 09:42:17.840529 28430 solver.cpp:237]     Train net output #0: loss = 0.0680949 (* 1 = 0.0680949 loss)
I1103 09:42:17.841183 28430 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I1103 09:42:21.245335 28430 solver.cpp:218] Iteration 2400 (29.3772 iter/s, 3.404s/100 iters), loss = 0.00964655
I1103 09:42:21.246093 28430 solver.cpp:237]     Train net output #0: loss = 0.00964642 (* 1 = 0.00964642 loss)
I1103 09:42:21.246753 28430 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I1103 09:42:24.622714 28430 solver.cpp:330] Iteration 2500, Testing net (#0)
I1103 09:42:27.226245 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:42:27.330704 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9819
I1103 09:42:27.331446 28430 solver.cpp:397]     Test net output #1: loss = 0.0524281 (* 1 = 0.0524281 loss)
I1103 09:42:27.370069 28430 solver.cpp:218] Iteration 2500 (16.3319 iter/s, 6.123s/100 iters), loss = 0.0307726
I1103 09:42:27.370820 28430 solver.cpp:237]     Train net output #0: loss = 0.0307725 (* 1 = 0.0307725 loss)
I1103 09:42:27.371454 28430 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I1103 09:42:30.779361 28430 solver.cpp:218] Iteration 2600 (29.3427 iter/s, 3.408s/100 iters), loss = 0.0589156
I1103 09:42:30.780133 28430 solver.cpp:237]     Train net output #0: loss = 0.0589155 (* 1 = 0.0589155 loss)
I1103 09:42:30.780766 28430 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I1103 09:42:34.189771 28430 solver.cpp:218] Iteration 2700 (29.3341 iter/s, 3.409s/100 iters), loss = 0.0669701
I1103 09:42:34.190507 28430 solver.cpp:237]     Train net output #0: loss = 0.06697 (* 1 = 0.06697 loss)
I1103 09:42:34.191125 28430 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I1103 09:42:37.620203 28430 solver.cpp:218] Iteration 2800 (29.163 iter/s, 3.429s/100 iters), loss = 0.00103625
I1103 09:42:37.620934 28430 solver.cpp:237]     Train net output #0: loss = 0.00103608 (* 1 = 0.00103608 loss)
I1103 09:42:37.621554 28430 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I1103 09:42:37.901932 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:42:41.048146 28430 solver.cpp:218] Iteration 2900 (29.18 iter/s, 3.427s/100 iters), loss = 0.0230369
I1103 09:42:41.048871 28430 solver.cpp:237]     Train net output #0: loss = 0.0230368 (* 1 = 0.0230368 loss)
I1103 09:42:41.049510 28430 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I1103 09:42:44.429179 28430 solver.cpp:330] Iteration 3000, Testing net (#0)
I1103 09:42:46.937527 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:42:47.041579 28430 solver.cpp:397]     Test net output #0: accuracy = 0.987
I1103 09:42:47.042341 28430 solver.cpp:397]     Test net output #1: loss = 0.0385952 (* 1 = 0.0385952 loss)
I1103 09:42:47.088337 28430 solver.cpp:218] Iteration 3000 (16.559 iter/s, 6.039s/100 iters), loss = 0.0363684
I1103 09:42:47.089045 28430 solver.cpp:237]     Train net output #0: loss = 0.0363683 (* 1 = 0.0363683 loss)
I1103 09:42:47.089676 28430 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I1103 09:42:50.506884 28430 solver.cpp:218] Iteration 3100 (29.2654 iter/s, 3.417s/100 iters), loss = 0.0152248
I1103 09:42:50.507748 28430 solver.cpp:237]     Train net output #0: loss = 0.0152246 (* 1 = 0.0152246 loss)
I1103 09:42:50.508400 28430 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I1103 09:42:53.928266 28430 solver.cpp:218] Iteration 3200 (29.2398 iter/s, 3.42s/100 iters), loss = 0.00499123
I1103 09:42:53.929282 28430 solver.cpp:237]     Train net output #0: loss = 0.00499106 (* 1 = 0.00499106 loss)
I1103 09:42:53.929913 28430 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I1103 09:42:57.352483 28430 solver.cpp:218] Iteration 3300 (29.2141 iter/s, 3.423s/100 iters), loss = 0.0176782
I1103 09:42:57.353278 28430 solver.cpp:237]     Train net output #0: loss = 0.017678 (* 1 = 0.017678 loss)
I1103 09:42:57.353907 28430 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I1103 09:43:00.769701 28430 solver.cpp:218] Iteration 3400 (29.274 iter/s, 3.416s/100 iters), loss = 0.0149262
I1103 09:43:00.770424 28430 solver.cpp:237]     Train net output #0: loss = 0.014926 (* 1 = 0.014926 loss)
I1103 09:43:00.771065 28430 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I1103 09:43:04.147915 28430 solver.cpp:330] Iteration 3500, Testing net (#0)
I1103 09:43:06.648898 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:43:06.751830 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9881
I1103 09:43:06.752534 28430 solver.cpp:397]     Test net output #1: loss = 0.0375466 (* 1 = 0.0375466 loss)
I1103 09:43:06.797778 28430 solver.cpp:218] Iteration 3500 (16.592 iter/s, 6.027s/100 iters), loss = 0.00655151
I1103 09:43:06.798507 28430 solver.cpp:237]     Train net output #0: loss = 0.00655135 (* 1 = 0.00655135 loss)
I1103 09:43:06.799123 28430 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I1103 09:43:10.209673 28430 solver.cpp:218] Iteration 3600 (29.3169 iter/s, 3.411s/100 iters), loss = 0.0310055
I1103 09:43:10.210427 28430 solver.cpp:237]     Train net output #0: loss = 0.0310053 (* 1 = 0.0310053 loss)
I1103 09:43:10.211042 28430 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I1103 09:43:13.652019 28430 solver.cpp:218] Iteration 3700 (29.0613 iter/s, 3.441s/100 iters), loss = 0.0285684
I1103 09:43:13.652096 28430 solver.cpp:237]     Train net output #0: loss = 0.0285682 (* 1 = 0.0285682 loss)
I1103 09:43:13.652115 28430 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I1103 09:43:15.232259 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:43:17.123021 28430 solver.cpp:218] Iteration 3800 (28.8184 iter/s, 3.47s/100 iters), loss = 0.00844308
I1103 09:43:17.123088 28430 solver.cpp:237]     Train net output #0: loss = 0.00844291 (* 1 = 0.00844291 loss)
I1103 09:43:17.123116 28430 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I1103 09:43:20.538377 28430 solver.cpp:218] Iteration 3900 (29.2826 iter/s, 3.415s/100 iters), loss = 0.0190239
I1103 09:43:20.538547 28430 solver.cpp:237]     Train net output #0: loss = 0.0190237 (* 1 = 0.0190237 loss)
I1103 09:43:20.538565 28430 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I1103 09:43:23.926232 28430 solver.cpp:330] Iteration 4000, Testing net (#0)
I1103 09:43:26.405782 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:43:26.509615 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9896
I1103 09:43:26.509677 28430 solver.cpp:397]     Test net output #1: loss = 0.0311345 (* 1 = 0.0311345 loss)
I1103 09:43:26.554021 28430 solver.cpp:218] Iteration 4000 (16.6251 iter/s, 6.015s/100 iters), loss = 0.0226173
I1103 09:43:26.554085 28430 solver.cpp:237]     Train net output #0: loss = 0.0226171 (* 1 = 0.0226171 loss)
I1103 09:43:26.554105 28430 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I1103 09:43:29.963320 28430 solver.cpp:218] Iteration 4100 (29.3341 iter/s, 3.409s/100 iters), loss = 0.0330833
I1103 09:43:29.964082 28430 solver.cpp:237]     Train net output #0: loss = 0.0330832 (* 1 = 0.0330832 loss)
I1103 09:43:29.964715 28430 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I1103 09:43:33.382009 28430 solver.cpp:218] Iteration 4200 (29.2654 iter/s, 3.417s/100 iters), loss = 0.010414
I1103 09:43:33.382728 28430 solver.cpp:237]     Train net output #0: loss = 0.0104138 (* 1 = 0.0104138 loss)
I1103 09:43:33.383368 28430 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I1103 09:43:36.829190 28430 solver.cpp:218] Iteration 4300 (29.0192 iter/s, 3.446s/100 iters), loss = 0.0577553
I1103 09:43:36.829898 28430 solver.cpp:237]     Train net output #0: loss = 0.0577552 (* 1 = 0.0577552 loss)
I1103 09:43:36.830539 28430 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I1103 09:43:40.297788 28430 solver.cpp:218] Iteration 4400 (28.8434 iter/s, 3.467s/100 iters), loss = 0.0131654
I1103 09:43:40.298521 28430 solver.cpp:237]     Train net output #0: loss = 0.0131653 (* 1 = 0.0131653 loss)
I1103 09:43:40.299162 28430 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I1103 09:43:43.697767 28430 solver.cpp:330] Iteration 4500, Testing net (#0)
I1103 09:43:46.181984 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:43:46.287240 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9881
I1103 09:43:46.287302 28430 solver.cpp:397]     Test net output #1: loss = 0.0348431 (* 1 = 0.0348431 loss)
I1103 09:43:46.332185 28430 solver.cpp:218] Iteration 4500 (16.5755 iter/s, 6.033s/100 iters), loss = 0.00309877
I1103 09:43:46.332247 28430 solver.cpp:237]     Train net output #0: loss = 0.00309863 (* 1 = 0.00309863 loss)
I1103 09:43:46.332265 28430 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I1103 09:43:49.772409 28430 solver.cpp:218] Iteration 4600 (29.0698 iter/s, 3.44s/100 iters), loss = 0.00582019
I1103 09:43:49.772480 28430 solver.cpp:237]     Train net output #0: loss = 0.00582004 (* 1 = 0.00582004 loss)
I1103 09:43:49.772497 28430 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I1103 09:43:52.623450 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:43:53.207110 28430 solver.cpp:218] Iteration 4700 (29.1206 iter/s, 3.434s/100 iters), loss = 0.0100118
I1103 09:43:53.207183 28430 solver.cpp:237]     Train net output #0: loss = 0.0100117 (* 1 = 0.0100117 loss)
I1103 09:43:53.207201 28430 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I1103 09:43:56.629456 28430 solver.cpp:218] Iteration 4800 (29.2227 iter/s, 3.422s/100 iters), loss = 0.0116494
I1103 09:43:56.629523 28430 solver.cpp:237]     Train net output #0: loss = 0.0116493 (* 1 = 0.0116493 loss)
I1103 09:43:56.629541 28430 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I1103 09:44:00.040122 28430 solver.cpp:218] Iteration 4900 (29.3255 iter/s, 3.41s/100 iters), loss = 0.00712056
I1103 09:44:00.040194 28430 solver.cpp:237]     Train net output #0: loss = 0.00712043 (* 1 = 0.00712043 loss)
I1103 09:44:00.040221 28430 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I1103 09:44:03.417722 28430 solver.cpp:447] Snapshotting to binary proto file lenet_iter_5000.caffemodel
I1103 09:44:03.422035 28430 sgd_solver.cpp:273] Snapshotting solver state to binary proto file lenet_iter_5000.solverstate
I1103 09:44:03.423678 28430 solver.cpp:330] Iteration 5000, Testing net (#0)
I1103 09:44:05.918118 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:44:06.022150 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9895
I1103 09:44:06.022833 28430 solver.cpp:397]     Test net output #1: loss = 0.0314825 (* 1 = 0.0314825 loss)
I1103 09:44:06.068594 28430 solver.cpp:218] Iteration 5000 (16.5893 iter/s, 6.028s/100 iters), loss = 0.0220925
I1103 09:44:06.069294 28430 solver.cpp:237]     Train net output #0: loss = 0.0220924 (* 1 = 0.0220924 loss)
I1103 09:44:06.069893 28430 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I1103 09:44:09.480444 28430 solver.cpp:218] Iteration 5100 (29.3169 iter/s, 3.411s/100 iters), loss = 0.0277358
I1103 09:44:09.481163 28430 solver.cpp:237]     Train net output #0: loss = 0.0277357 (* 1 = 0.0277357 loss)
I1103 09:44:09.481792 28430 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I1103 09:44:12.890511 28430 solver.cpp:218] Iteration 5200 (29.3341 iter/s, 3.409s/100 iters), loss = 0.00611199
I1103 09:44:12.891260 28430 solver.cpp:237]     Train net output #0: loss = 0.00611186 (* 1 = 0.00611186 loss)
I1103 09:44:12.891888 28430 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I1103 09:44:16.312630 28430 solver.cpp:218] Iteration 5300 (29.2312 iter/s, 3.421s/100 iters), loss = 0.00187257
I1103 09:44:16.313369 28430 solver.cpp:237]     Train net output #0: loss = 0.00187243 (* 1 = 0.00187243 loss)
I1103 09:44:16.313984 28430 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I1103 09:44:19.838251 28430 solver.cpp:218] Iteration 5400 (28.3768 iter/s, 3.524s/100 iters), loss = 0.00700525
I1103 09:44:19.838964 28430 solver.cpp:237]     Train net output #0: loss = 0.00700511 (* 1 = 0.00700511 loss)
I1103 09:44:19.839573 28430 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I1103 09:44:23.584481 28430 solver.cpp:330] Iteration 5500, Testing net (#0)
I1103 09:44:26.072732 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:44:26.175823 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9892
I1103 09:44:26.176520 28430 solver.cpp:397]     Test net output #1: loss = 0.0327172 (* 1 = 0.0327172 loss)
I1103 09:44:26.221539 28430 solver.cpp:218] Iteration 5500 (15.6691 iter/s, 6.382s/100 iters), loss = 0.0106368
I1103 09:44:26.222242 28430 solver.cpp:237]     Train net output #0: loss = 0.0106367 (* 1 = 0.0106367 loss)
I1103 09:44:26.222848 28430 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I1103 09:44:29.649755 28430 solver.cpp:218] Iteration 5600 (29.18 iter/s, 3.427s/100 iters), loss = 0.00176676
I1103 09:44:29.649830 28430 solver.cpp:237]     Train net output #0: loss = 0.00176663 (* 1 = 0.00176663 loss)
I1103 09:44:29.649849 28430 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I1103 09:44:30.344157 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:44:33.073081 28430 solver.cpp:218] Iteration 5700 (29.2141 iter/s, 3.423s/100 iters), loss = 0.0030107
I1103 09:44:33.073771 28430 solver.cpp:237]     Train net output #0: loss = 0.00301055 (* 1 = 0.00301055 loss)
I1103 09:44:33.074379 28430 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I1103 09:44:36.507287 28430 solver.cpp:218] Iteration 5800 (29.129 iter/s, 3.433s/100 iters), loss = 0.0212981
I1103 09:44:36.507977 28430 solver.cpp:237]     Train net output #0: loss = 0.0212979 (* 1 = 0.0212979 loss)
I1103 09:44:36.508584 28430 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I1103 09:44:39.923446 28430 solver.cpp:218] Iteration 5900 (29.2826 iter/s, 3.415s/100 iters), loss = 0.00739589
I1103 09:44:39.924160 28430 solver.cpp:237]     Train net output #0: loss = 0.00739575 (* 1 = 0.00739575 loss)
I1103 09:44:39.924777 28430 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I1103 09:44:43.314484 28430 solver.cpp:330] Iteration 6000, Testing net (#0)
I1103 09:44:45.799520 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:44:45.902597 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9906
I1103 09:44:45.903292 28430 solver.cpp:397]     Test net output #1: loss = 0.0298086 (* 1 = 0.0298086 loss)
I1103 09:44:45.947571 28430 solver.cpp:218] Iteration 6000 (16.603 iter/s, 6.023s/100 iters), loss = 0.00353576
I1103 09:44:45.948246 28430 solver.cpp:237]     Train net output #0: loss = 0.00353562 (* 1 = 0.00353562 loss)
I1103 09:44:45.948823 28430 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I1103 09:44:49.360361 28430 solver.cpp:218] Iteration 6100 (29.3083 iter/s, 3.412s/100 iters), loss = 0.00515428
I1103 09:44:49.361090 28430 solver.cpp:237]     Train net output #0: loss = 0.00515414 (* 1 = 0.00515414 loss)
I1103 09:44:49.361671 28430 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I1103 09:44:52.791234 28430 solver.cpp:218] Iteration 6200 (29.1545 iter/s, 3.43s/100 iters), loss = 0.00819867
I1103 09:44:52.791923 28430 solver.cpp:237]     Train net output #0: loss = 0.00819853 (* 1 = 0.00819853 loss)
I1103 09:44:52.792512 28430 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I1103 09:44:56.220032 28430 solver.cpp:218] Iteration 6300 (29.1715 iter/s, 3.428s/100 iters), loss = 0.00925953
I1103 09:44:56.220826 28430 solver.cpp:237]     Train net output #0: loss = 0.00925936 (* 1 = 0.00925936 loss)
I1103 09:44:56.221412 28430 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I1103 09:44:59.646142 28430 solver.cpp:218] Iteration 6400 (29.1971 iter/s, 3.425s/100 iters), loss = 0.00700668
I1103 09:44:59.646855 28430 solver.cpp:237]     Train net output #0: loss = 0.0070065 (* 1 = 0.0070065 loss)
I1103 09:44:59.647449 28430 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I1103 09:45:03.042892 28430 solver.cpp:330] Iteration 6500, Testing net (#0)
I1103 09:45:05.537595 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:45:05.651762 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9896
I1103 09:45:05.651823 28430 solver.cpp:397]     Test net output #1: loss = 0.0321515 (* 1 = 0.0321515 loss)
I1103 09:45:05.695891 28430 solver.cpp:218] Iteration 6500 (16.5317 iter/s, 6.049s/100 iters), loss = 0.0103186
I1103 09:45:05.695951 28430 solver.cpp:237]     Train net output #0: loss = 0.0103185 (* 1 = 0.0103185 loss)
I1103 09:45:05.695968 28430 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I1103 09:45:07.698510 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:45:09.135023 28430 solver.cpp:218] Iteration 6600 (29.0782 iter/s, 3.439s/100 iters), loss = 0.0115728
I1103 09:45:09.135092 28430 solver.cpp:237]     Train net output #0: loss = 0.0115727 (* 1 = 0.0115727 loss)
I1103 09:45:09.135109 28430 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I1103 09:45:12.545328 28430 solver.cpp:218] Iteration 6700 (29.3255 iter/s, 3.41s/100 iters), loss = 0.00867651
I1103 09:45:12.545400 28430 solver.cpp:237]     Train net output #0: loss = 0.00867634 (* 1 = 0.00867634 loss)
I1103 09:45:12.545418 28430 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I1103 09:45:15.973716 28430 solver.cpp:218] Iteration 6800 (29.1715 iter/s, 3.428s/100 iters), loss = 0.00239655
I1103 09:45:15.973790 28430 solver.cpp:237]     Train net output #0: loss = 0.00239637 (* 1 = 0.00239637 loss)
I1103 09:45:15.973809 28430 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I1103 09:45:19.394897 28430 solver.cpp:218] Iteration 6900 (29.2312 iter/s, 3.421s/100 iters), loss = 0.00439989
I1103 09:45:19.394968 28430 solver.cpp:237]     Train net output #0: loss = 0.00439971 (* 1 = 0.00439971 loss)
I1103 09:45:19.394986 28430 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I1103 09:45:22.808528 28430 solver.cpp:330] Iteration 7000, Testing net (#0)
I1103 09:45:25.277904 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:45:25.383227 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9901
I1103 09:45:25.383288 28430 solver.cpp:397]     Test net output #1: loss = 0.0294657 (* 1 = 0.0294657 loss)
I1103 09:45:25.427281 28430 solver.cpp:218] Iteration 7000 (16.5782 iter/s, 6.032s/100 iters), loss = 0.00647233
I1103 09:45:25.427345 28430 solver.cpp:237]     Train net output #0: loss = 0.00647215 (* 1 = 0.00647215 loss)
I1103 09:45:25.427363 28430 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I1103 09:45:28.851649 28430 solver.cpp:218] Iteration 7100 (29.2056 iter/s, 3.424s/100 iters), loss = 0.0151624
I1103 09:45:28.851828 28430 solver.cpp:237]     Train net output #0: loss = 0.0151623 (* 1 = 0.0151623 loss)
I1103 09:45:28.851847 28430 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I1103 09:45:32.275501 28430 solver.cpp:218] Iteration 7200 (29.2141 iter/s, 3.423s/100 iters), loss = 0.00856639
I1103 09:45:32.275578 28430 solver.cpp:237]     Train net output #0: loss = 0.00856621 (* 1 = 0.00856621 loss)
I1103 09:45:32.275595 28430 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I1103 09:45:35.685247 28430 solver.cpp:218] Iteration 7300 (29.3341 iter/s, 3.409s/100 iters), loss = 0.0206414
I1103 09:45:35.685492 28430 solver.cpp:237]     Train net output #0: loss = 0.0206413 (* 1 = 0.0206413 loss)
I1103 09:45:35.685508 28430 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I1103 09:45:39.111291 28430 solver.cpp:218] Iteration 7400 (29.1971 iter/s, 3.425s/100 iters), loss = 0.00374739
I1103 09:45:39.111367 28430 solver.cpp:237]     Train net output #0: loss = 0.00374724 (* 1 = 0.00374724 loss)
I1103 09:45:39.111387 28430 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I1103 09:45:42.392439 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:45:42.538393 28430 solver.cpp:330] Iteration 7500, Testing net (#0)
I1103 09:45:45.033957 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:45:45.136574 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9898
I1103 09:45:45.137284 28430 solver.cpp:397]     Test net output #1: loss = 0.0327972 (* 1 = 0.0327972 loss)
I1103 09:45:45.182224 28430 solver.cpp:218] Iteration 7500 (16.4745 iter/s, 6.07s/100 iters), loss = 0.0010774
I1103 09:45:45.182948 28430 solver.cpp:237]     Train net output #0: loss = 0.00107725 (* 1 = 0.00107725 loss)
I1103 09:45:45.183542 28430 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I1103 09:45:48.614720 28430 solver.cpp:218] Iteration 7600 (29.146 iter/s, 3.431s/100 iters), loss = 0.00768636
I1103 09:45:48.615408 28430 solver.cpp:237]     Train net output #0: loss = 0.00768621 (* 1 = 0.00768621 loss)
I1103 09:45:48.616003 28430 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I1103 09:45:52.046946 28430 solver.cpp:218] Iteration 7700 (29.146 iter/s, 3.431s/100 iters), loss = 0.0324864
I1103 09:45:52.047633 28430 solver.cpp:237]     Train net output #0: loss = 0.0324862 (* 1 = 0.0324862 loss)
I1103 09:45:52.048240 28430 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I1103 09:45:55.493347 28430 solver.cpp:218] Iteration 7800 (29.0276 iter/s, 3.445s/100 iters), loss = 0.00497037
I1103 09:45:55.494076 28430 solver.cpp:237]     Train net output #0: loss = 0.00497023 (* 1 = 0.00497023 loss)
I1103 09:45:55.494679 28430 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I1103 09:45:58.923252 28430 solver.cpp:218] Iteration 7900 (29.163 iter/s, 3.429s/100 iters), loss = 0.00575191
I1103 09:45:58.924039 28430 solver.cpp:237]     Train net output #0: loss = 0.00575176 (* 1 = 0.00575176 loss)
I1103 09:45:58.924633 28430 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I1103 09:46:02.322098 28430 solver.cpp:330] Iteration 8000, Testing net (#0)
I1103 09:46:04.820134 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:46:04.925006 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9901
I1103 09:46:04.925647 28430 solver.cpp:397]     Test net output #1: loss = 0.0307635 (* 1 = 0.0307635 loss)
I1103 09:46:04.970376 28430 solver.cpp:218] Iteration 8000 (16.5399 iter/s, 6.046s/100 iters), loss = 0.0078307
I1103 09:46:04.971091 28430 solver.cpp:237]     Train net output #0: loss = 0.00783056 (* 1 = 0.00783056 loss)
I1103 09:46:04.971686 28430 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I1103 09:46:08.393311 28430 solver.cpp:218] Iteration 8100 (29.2227 iter/s, 3.422s/100 iters), loss = 0.00902146
I1103 09:46:08.393998 28430 solver.cpp:237]     Train net output #0: loss = 0.00902133 (* 1 = 0.00902133 loss)
I1103 09:46:08.394592 28430 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I1103 09:46:11.819275 28430 solver.cpp:218] Iteration 8200 (29.1971 iter/s, 3.425s/100 iters), loss = 0.00580042
I1103 09:46:11.819947 28430 solver.cpp:237]     Train net output #0: loss = 0.00580029 (* 1 = 0.00580029 loss)
I1103 09:46:11.820535 28430 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I1103 09:46:15.251544 28430 solver.cpp:218] Iteration 8300 (29.146 iter/s, 3.431s/100 iters), loss = 0.0225991
I1103 09:46:15.252223 28430 solver.cpp:237]     Train net output #0: loss = 0.0225989 (* 1 = 0.0225989 loss)
I1103 09:46:15.252806 28430 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I1103 09:46:18.759676 28430 solver.cpp:218] Iteration 8400 (28.5144 iter/s, 3.507s/100 iters), loss = 0.00569999
I1103 09:46:18.760396 28430 solver.cpp:237]     Train net output #0: loss = 0.00569986 (* 1 = 0.00569986 loss)
I1103 09:46:18.760982 28430 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I1103 09:46:19.996314 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:46:22.249464 28430 solver.cpp:330] Iteration 8500, Testing net (#0)
I1103 09:46:24.733942 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:46:24.837597 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9907
I1103 09:46:24.838259 28430 solver.cpp:397]     Test net output #1: loss = 0.0300188 (* 1 = 0.0300188 loss)
I1103 09:46:24.882939 28430 solver.cpp:218] Iteration 8500 (16.3345 iter/s, 6.122s/100 iters), loss = 0.00757651
I1103 09:46:24.883785 28430 solver.cpp:237]     Train net output #0: loss = 0.00757637 (* 1 = 0.00757637 loss)
I1103 09:46:24.884394 28430 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I1103 09:46:28.321427 28430 solver.cpp:218] Iteration 8600 (29.0951 iter/s, 3.437s/100 iters), loss = 0.000937536
I1103 09:46:28.322145 28430 solver.cpp:237]     Train net output #0: loss = 0.000937396 (* 1 = 0.000937396 loss)
I1103 09:46:28.322757 28430 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I1103 09:46:31.748499 28430 solver.cpp:218] Iteration 8700 (29.1886 iter/s, 3.426s/100 iters), loss = 0.00221982
I1103 09:46:31.749333 28430 solver.cpp:237]     Train net output #0: loss = 0.00221968 (* 1 = 0.00221968 loss)
I1103 09:46:31.749930 28430 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I1103 09:46:35.170616 28430 solver.cpp:218] Iteration 8800 (29.2312 iter/s, 3.421s/100 iters), loss = 0.00129865
I1103 09:46:35.171288 28430 solver.cpp:237]     Train net output #0: loss = 0.0012985 (* 1 = 0.0012985 loss)
I1103 09:46:35.171887 28430 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I1103 09:46:38.589401 28430 solver.cpp:218] Iteration 8900 (29.2569 iter/s, 3.418s/100 iters), loss = 0.000562661
I1103 09:46:38.590126 28430 solver.cpp:237]     Train net output #0: loss = 0.000562521 (* 1 = 0.000562521 loss)
I1103 09:46:38.590718 28430 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I1103 09:46:41.972049 28430 solver.cpp:330] Iteration 9000, Testing net (#0)
I1103 09:46:44.462273 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:46:44.577442 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9894
I1103 09:46:44.578091 28430 solver.cpp:397]     Test net output #1: loss = 0.0305887 (* 1 = 0.0305887 loss)
I1103 09:46:44.622447 28430 solver.cpp:218] Iteration 9000 (16.5782 iter/s, 6.032s/100 iters), loss = 0.0157748
I1103 09:46:44.623126 28430 solver.cpp:237]     Train net output #0: loss = 0.0157746 (* 1 = 0.0157746 loss)
I1103 09:46:44.623711 28430 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I1103 09:46:48.037818 28430 solver.cpp:218] Iteration 9100 (29.2912 iter/s, 3.414s/100 iters), loss = 0.00739945
I1103 09:46:48.038519 28430 solver.cpp:237]     Train net output #0: loss = 0.00739931 (* 1 = 0.00739931 loss)
I1103 09:46:48.039130 28430 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I1103 09:46:51.457954 28430 solver.cpp:218] Iteration 9200 (29.2483 iter/s, 3.419s/100 iters), loss = 0.00352766
I1103 09:46:51.458648 28430 solver.cpp:237]     Train net output #0: loss = 0.00352752 (* 1 = 0.00352752 loss)
I1103 09:46:51.459256 28430 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I1103 09:46:54.875679 28430 solver.cpp:218] Iteration 9300 (29.2654 iter/s, 3.417s/100 iters), loss = 0.00520748
I1103 09:46:54.876405 28430 solver.cpp:237]     Train net output #0: loss = 0.00520734 (* 1 = 0.00520734 loss)
I1103 09:46:54.876986 28430 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I1103 09:46:57.317867 28442 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:46:58.343317 28430 solver.cpp:218] Iteration 9400 (28.8517 iter/s, 3.466s/100 iters), loss = 0.0183106
I1103 09:46:58.344012 28430 solver.cpp:237]     Train net output #0: loss = 0.0183105 (* 1 = 0.0183105 loss)
I1103 09:46:58.344624 28430 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I1103 09:47:01.740869 28430 solver.cpp:330] Iteration 9500, Testing net (#0)
I1103 09:47:04.245710 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:47:04.360301 28430 solver.cpp:397]     Test net output #0: accuracy = 0.987
I1103 09:47:04.360369 28430 solver.cpp:397]     Test net output #1: loss = 0.0399926 (* 1 = 0.0399926 loss)
I1103 09:47:04.407138 28430 solver.cpp:218] Iteration 9500 (16.4935 iter/s, 6.063s/100 iters), loss = 0.00270895
I1103 09:47:04.407212 28430 solver.cpp:237]     Train net output #0: loss = 0.0027088 (* 1 = 0.0027088 loss)
I1103 09:47:04.407233 28430 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I1103 09:47:07.825153 28430 solver.cpp:218] Iteration 9600 (29.2654 iter/s, 3.417s/100 iters), loss = 0.00255655
I1103 09:47:07.825225 28430 solver.cpp:237]     Train net output #0: loss = 0.00255641 (* 1 = 0.00255641 loss)
I1103 09:47:07.825243 28430 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I1103 09:47:11.256953 28430 solver.cpp:218] Iteration 9700 (29.146 iter/s, 3.431s/100 iters), loss = 0.0033185
I1103 09:47:11.257026 28430 solver.cpp:237]     Train net output #0: loss = 0.00331836 (* 1 = 0.00331836 loss)
I1103 09:47:11.257043 28430 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I1103 09:47:14.686542 28430 solver.cpp:218] Iteration 9800 (29.163 iter/s, 3.429s/100 iters), loss = 0.00949836
I1103 09:47:14.686616 28430 solver.cpp:237]     Train net output #0: loss = 0.00949822 (* 1 = 0.00949822 loss)
I1103 09:47:14.686633 28430 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I1103 09:47:18.143687 28430 solver.cpp:218] Iteration 9900 (28.9268 iter/s, 3.457s/100 iters), loss = 0.00691712
I1103 09:47:18.143967 28430 solver.cpp:237]     Train net output #0: loss = 0.00691698 (* 1 = 0.00691698 loss)
I1103 09:47:18.143986 28430 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I1103 09:47:21.659447 28430 solver.cpp:447] Snapshotting to binary proto file lenet_iter_10000.caffemodel
I1103 09:47:21.662179 28430 sgd_solver.cpp:273] Snapshotting solver state to binary proto file lenet_iter_10000.solverstate
I1103 09:47:21.680529 28430 solver.cpp:310] Iteration 10000, loss = 0.00377547
I1103 09:47:21.681191 28430 solver.cpp:330] Iteration 10000, Testing net (#0)
I1103 09:47:24.215916 28443 data_layer.cpp:73] Restarting data prefetching from start.
I1103 09:47:24.317932 28430 solver.cpp:397]     Test net output #0: accuracy = 0.9906
I1103 09:47:24.317996 28430 solver.cpp:397]     Test net output #1: loss = 0.0287233 (* 1 = 0.0287233 loss)
I1103 09:47:24.318012 28430 solver.cpp:315] Optimization Done.
I1103 09:47:24.318024 28430 caffe.cpp:259] Optimization Done.

real 6m42.900s
user 21m24.824s
sys 31m46.724s
